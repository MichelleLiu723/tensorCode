{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_repeated_Indices(list_of_indices):\n",
    "    #input: string of indices for the tensors. \n",
    "    #output: string of repeated indices. code takes in indices and output only the repeated indices\n",
    "    #Ex: Suppose tensor A has index ijkp, and tensor B has index klpm.\n",
    "    #then get_repeated_Indices('ijkp', 'klpm') will return the following string: 'kp'\n",
    "    myList = list_of_indices\n",
    "    #convert List to string\n",
    "    myString =''.join(myList)\n",
    "    #break the string into indivual list of characters ex.  'abc' ->['a','b', 'c']\n",
    "    myList = list(myString)\n",
    "    #get the repeated frequencies of each indices\n",
    "    my_dict = {i:myList.count(i) for i in myList}\n",
    "    \n",
    "    repeatedList = []\n",
    "    for item in my_dict:\n",
    "        if my_dict[item] > 1:\n",
    "            repeatedList.append(item)\n",
    "    return repeatedList\n",
    "\n",
    "def  remove_Repeated_indices(List_of_indices):\n",
    "    #inputs: tensor indices in the form of string\n",
    "    #output: string of non repeated indicies\n",
    "    #Ex: remove_Repeated_indices('abc', 'cde')\n",
    "    #output of the example would be: 'abde'\n",
    "    \n",
    "    myList = List_of_indices \n",
    "    #turn myList into String: Ex: ['abc','cde'] -> 'abccde'\n",
    "    myString = ''.join(myList)\n",
    "    #turn back into lists again: Exp: from 'abccde' -> ['a','b','c','c','d','e']\n",
    "    myList = list(myString)\n",
    "    repeated_indices = get_repeated_Indices(List_of_indices)\n",
    "    #print('the repeated list of indices are:', repeated_indices)\n",
    "    unique_indices = []\n",
    "    #now we remove repeated indices from myList\n",
    "    for item in myList:\n",
    "        if item not in repeated_indices:\n",
    "            unique_indices.append(item)\n",
    "    uniqueString = ''.join(unique_indices)   \n",
    "    return uniqueString\n",
    "\n",
    "def einSum_Contraction(tensorList, indxList):  #<----should rename this to einSum_Contraction to replace old code\n",
    "    #Purpose: this function takes a list of tensors, and list of indices, and indix to contract and uses einstien summation to perform contraction\n",
    "    #ex: tensorList = [tensor1, tensor2, tensor3]\n",
    "    #indxList   = [indx1, indx2, indx3]\n",
    "    myList = []\n",
    "    uniqueIndices = remove_Repeated_indices(indxList)\n",
    "    inputIndices = [indxList]\n",
    "    N = len(indxList)\n",
    "    #myList = [indx1, ',',indx2,',',indx3,'->', uniqueIndices] \n",
    "    for i in range(N - 1):\n",
    "        myList.append(indxList[i])\n",
    "        myList.append(',') \n",
    "    myList.append(indxList[N-1])\n",
    "    myList.append('->')\n",
    "    myList.append(uniqueIndices)\n",
    "    #convert myList to a string: i.e.  [indx1, ',',indx2,',',indx3,'->', uniqueIndices]  - >'ijk,klm,mjp->ilp'\n",
    "    myString = ''.join(myList)\n",
    "    #print('myString = ', myString)\n",
    "    C = torch.einsum(myString, tensorList)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padTensor(tensor, pad_axis):\n",
    "    #this is for the discrete optimization\n",
    "    #this function takes a tensor and append an extra dimension of ~ zeros along the specified axis (we call the pad axis)\n",
    "    if pad_axis == -1:\n",
    "        return tensor #don't pad anything\n",
    "    tensorShape = list(tensor.shape)\n",
    "    tensorShape[pad_axis] = 1  #increase the dimension up by 1\n",
    "    zerosPad = torch.rand(tensorShape) *1e-6  #pad with values approx. equal to zero\n",
    "    padded_tensor = torch.cat([tensor, zerosPad], pad_axis)\n",
    "    #print('padded_tensor.shape = ', padded_tensor.shape)\n",
    "    #print('padded_tensor function output = ', padded_tensor)\n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def increaseRank(Tensor1, Tensor2, indx1, indx2):\n",
    "    # The indx 1 and index2 represents the indices for tensor 1 and 2 respectively. \n",
    "    #There is only one repeated index in the list (indx1, indx2). The repeated index represents the shared edge between\n",
    "    #the two tensors. For ex: ijkl, lmno\n",
    "    alpha = get_repeated_Indices([indx1, indx2])\n",
    "    if len(alpha) != 0 :\n",
    "        #convert alpha to string\n",
    "        alpha = ''.join(alpha)\n",
    "        # find the position of the repeated index alpha in indx1 and indx2\n",
    "        padAxes1 = indx1.index(alpha)\n",
    "        padAxes2 = indx2.index(alpha)  \n",
    "        Tensor1 = padTensor(Tensor1, padAxes1)\n",
    "        Tensor2 = padTensor(Tensor2, padAxes2)\n",
    "    return  Tensor1, Tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Tensor_Generator(TensorDimension):\n",
    "#input: desired target tensor dimension in the form of a list. Ex: input d1xd2xd3 as [d1, d2, d3]\n",
    "#output: target tensor with random entries drawn from a normal distribution of mean=0 and variance=1\n",
    "    Tensor = torch.randn(TensorDimension)\n",
    "    return Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOneData_point(W):\n",
    "# W is input tensor\n",
    "#X are drawn from a normal distribution of mean=0 and variance=1 \n",
    "#output: Xi, yi  = targetTensor * X\n",
    "    indxList = []\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    Xi = Tensor_Generator(W.shape) #generate Tensor Xi with same shape as input tensor W\n",
    "    for j in range(len(Xi.shape)):\n",
    "        indxList.append(alphabet[j])\n",
    "        indx = ''.join(indxList)\n",
    "    tensorList = [W, Xi]\n",
    "    #W and X have same index so that yi is a scaler\n",
    "    yi = einSum_Contraction([W,Xi], [indx, indx])\n",
    "    return Xi, yi, indx  #W and Xi shares the same indx\n",
    "\n",
    "def data_Set_Generator(tensor, N):\n",
    "    #N = number of training data you want\n",
    "    #tensor is usually the target tensor \n",
    "    Xi_set = []\n",
    "    yi_set = []\n",
    "    for i in range(N):\n",
    "        Xi, yi, indx = getOneData_point(tensor)\n",
    "        Xi_set.append(Xi)\n",
    "        yi_set.append(yi)\n",
    "    return Xi_set, yi_set,indx  #tensor and Xi shares the same indx\n",
    "\n",
    "def getYi_set(Xi_set, tensor, indxList):\n",
    "    #this function generates a N number of yi's using yi = tensor*Xi_set[i]. \n",
    "    #The input tensor is usually either the approx. tensor or the target tensor.\n",
    "    #indxList = [indx_Xi, indx_tensor]\n",
    "    yi_set = []\n",
    "    N = len(Xi_set)      #is there are N elements of Xi in Xi_set, there will be N elements of yi in yi_set\n",
    "    for i in range(N):\n",
    "        yi = einSum_Contraction([tensor,Xi_set[i]], indxList)\n",
    "        yi_set.append(yi)\n",
    "    return yi_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def innerProduct_Tensor(T,A):\n",
    "    #input: inner product of two tensors T and A of same dimension equals the sum of the product of their entries \n",
    "    #covert T, and A tensors in to 1 D tensors\n",
    "    T = T.view(1,-1)   #convert tensor  to 1D\n",
    "    T = T.squeeze()    #squeeze out any extra dimension\n",
    "    A = A.view(1,-1)\n",
    "    A = A.squeeze()\n",
    "    #perform inner product of two 1D tensors\n",
    "    yi = sum(torch.mul(T,A))\n",
    "    return yi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printRank(TensorList):\n",
    "    [r5,r6,r7,r8] = (TensorList[4].shape) #tensor G dimension\n",
    "    [r4,d4,r3,r5] = (TensorList[3].shape) #tensor D dimension\n",
    "    [r2,d1,r1,r7] = (TensorList[0].shape) #tensor A dimension\n",
    "    #print(' [r1, r2, r3,r4,r5,r6,r7,r8] = ', '[', r1, ',', r2, ',', r3, ',', r4, ',', r5,',', r6, ',', r7, ',', r8, ']')\n",
    "    r = [r1,r2,r3,r4,r5,r6,r7,r8]\n",
    "    return r\n",
    "\n",
    "\n",
    "def getNumParams(r):\n",
    "    #r = list of ranks of a tensor\n",
    "    numParam = d1*r[0]*r[6]*r[1] + d2*r[0]*r[7]*r[3]+ d3*r[1]*r[5]*r[2] + d4*r[3]*r[4]*r[2] + r[4]*r[5]*r[6]*r[7]\n",
    "    return numParam\n",
    "\n",
    "def getNumParams_stoch(r):\n",
    "    #r = [r0,r1,r2,r3,...,r7] \n",
    "    #we want to compuate the dimension of the block we start with. For exmape\n",
    "    #we started with 4 order tensor, which can be approximated by 5 tensors\n",
    "    #below computes the number of params for each of the tensor\n",
    "    numParam1 = d1*r[0]*r[6]*r[1]\n",
    "    numParam2 = d2*r[0]*r[7]*r[3]\n",
    "    numParam3 = d3*r[1]*r[5]*r[2]\n",
    "    numParam4 = d4*r[3]*r[4]*r[2]\n",
    "    numParamCore = r[4]*r[5]*r[6]*r[7] \n",
    "    numParamList = [numParam1, numParam2, numParam3, numParam4, numParamCore]\n",
    "    return numParamList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeLoss_Regression(yi_set, Xi_set, approxTensor):\n",
    "    #N is total number of training/test data\n",
    "    sum = 0\n",
    "    N = len(yi_set)\n",
    "    for i in range(N):\n",
    "        # y_approx = innerProduct(ApproxTensor, X_i)\n",
    "        y_approx = innerProduct_Tensor(approxTensor, Xi_set[i])\n",
    "        loss = (yi_set[i] - y_approx)**2\n",
    "        sum = sum + loss\n",
    "    #divide by N to average the squared error of the cost function  so that the cost function doesn't depend on the number \n",
    "    #of elements in the training set.\n",
    "    total_loss = 1/(2*N)*sum \n",
    "    return(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_RandomSeqence(seqLength,d):\n",
    "    #the function generates a random sequence of length 'seqLength' with range from 1 to range d.\n",
    "    #For examplae, if we have 8 ranks, then seqLength. Code will generate 8 random numbers in the range between \n",
    "    #1 to d inclusive.\n",
    "    r = []\n",
    "    for i in range(seqLength):\n",
    "        r.append(random.randint(1,d))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Next_randomEdge(r_list):\n",
    "    #this function is for random walk\n",
    "    #input: r_list = [r0,r1,...r7] \n",
    "    nextDirection = random.randint(0, len(r_list)-1)\n",
    "    print('nextDirection = ', nextDirection)\n",
    "    r_list[nextDirection] = 1 + r_list[nextDirection]\n",
    "    return r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_Continuous(target_Tensor, tensorList, indxList, iterNum):\n",
    "#input: list of tensors and their corresponding indices\n",
    "#Goal: The purpose of this function is to solve the innerloop of the optimization for the problem\n",
    "    len_Tensor = len(tensorList)\n",
    "    len_Indx   = len(indxList)\n",
    "    for i in range(len_Tensor):\n",
    "        tensorList[i] = tensorList[i].detach()\n",
    "        tensorList[i].requires_grad = True\n",
    "    #defines a SGD optimizer to update the parameters\n",
    "    #optimizer = optim.SGD(tensorList lr = 0.001, momentum=0.2)\n",
    "    optimizer = optim.Adam(tensorList, lr=0.009)\n",
    "    #initialize parameters      \n",
    "    LostList = []              #use this to plot the lost function\n",
    "    for i in range(iterNum):\n",
    "        optimizer.zero_grad()\n",
    "        tensor_approx = einSum_Contraction(tensorList, indxList)\n",
    "        #loss_fn = computeLoss(tensor_approx, target_Tensor)   # this is for tensor decomp: ||W_target - W_approx||_FË†2\n",
    "        loss_fn =computeLoss_Regression(yi_train, Xi_train, tensor_approx)\n",
    "        loss_fn.backward()\n",
    "        optimizer.step()                # the new A,B,C will be A_k+1,B_k+1, C_k+1 after optimizer.step \n",
    "        LostList.append(float(loss_fn))\n",
    "    return tensorList, indxList, LostList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate 4-order target tensor\n",
    "#see ipad for supplementary notes on this tensor and its diagram\n",
    "\n",
    "#With Core tensor: 5 nodes\n",
    "#****it will be interestingn to set r5 to r8 to get tucker structure and run the code to see how \n",
    "# the structure compares to tucker decomposition. Tucker decomposition could become another based cased\n",
    "d1 = 3\n",
    "d2 = 3\n",
    "d3 = 3\n",
    "d4 = 3\n",
    "d5 = 3\n",
    "r0 = 2\n",
    "r1 = 3\n",
    "r2 = 4\n",
    "r3 = 3\n",
    "r4 = 2\n",
    "r5 = 3\n",
    "r6 = 2\n",
    "r7 = 2\n",
    "\n",
    "noise = 1e-6\n",
    "#generate at random target tensor\n",
    "\n",
    "A = torch.rand(r1,d1,r0,r6) # + torch.rand(r1,d1,r0,r6)*noise\n",
    "B = torch.rand(r0,d2,r3,r7) # + torch.rand(r0,d2,r3,r7)*noise\n",
    "C = torch.rand(r1,d3,r2,r5) # + torch.rand(r1,d3,r2,r5)*noise\n",
    "D = torch.rand(r3,d4,r2,r4) # + torch.rand(r3,d4,r2,r4)*noise \n",
    "G = torch.rand(r4,r5,r6,r7) # + torch.rand(r4,r5,r6,r7)*noise\n",
    "\n",
    "indxA = 'kilc'\n",
    "indxB = 'ljed'\n",
    "indxC = 'khgb'\n",
    "indxD = 'efga'\n",
    "indxG = 'abcd'   #core tensor\n",
    "\n",
    "indxList = [indxA, indxB, indxC, indxD, indxG]\n",
    "\n",
    "target_Tensor = einSum_Contraction([A,B,C,D,G], [indxA, indxB, indxC, indxD, indxG])\n",
    "\n",
    "\n",
    "#generate training and test sets\n",
    "N=20\n",
    "#p is the percentage of the total number of data N\n",
    "p = int(np.floor(0.65*20))  #so is is 65% of the original data\n",
    "[Xi_data, yi_data, indx] = data_Set_Generator(target_Tensor, N) \n",
    "Xi_train = Xi_data[0:p]\n",
    "yi_train  = yi_data[0:p]\n",
    "Xi_test = Xi_data[p:N+1]\n",
    "yi_test = yi_data[p:N+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#following data are used for initializing Greedy method\n",
    "\n",
    "#initilize data\n",
    "r1 = 1\n",
    "r2 = 1\n",
    "r3 = 1\n",
    "r4 = 1\n",
    "r5 = 1\n",
    "r6 = 1\n",
    "r7 = 1\n",
    "r8 = 1\n",
    "\n",
    "#initialize tensor \n",
    "A_0 = torch.rand(r2,d1,r1,r7)\n",
    "B_0 = torch.rand(r1,d2,r4,r8)\n",
    "C_0 = torch.rand(r2,d3,r3,r6) \n",
    "D_0 = torch.rand(r4,d4,r3,r5) \n",
    "G_0 = torch.rand(r5,r6,r7,r8)\n",
    "\n",
    "#target_Tensor = einSum_Contraction([A_0,B_0,C_0,D_0,G_0], [indxA, indxB, indxC, indxD, indxG])\n",
    "\n",
    "\n",
    "TensorList = [A_0,B_0,C_0,D_0,G_0] \n",
    "TensorList_temp = [A_0,B_0,C_0,D_0,G_0] #TensorList[:]\n",
    "\n",
    "#index list: we use the same indexlist as the ones defiined for target tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numParam_greedy= 19\n",
      "r_greedy =  [2, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 13\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 2, 1]\n",
      "numParam_greedy= 13\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 1, 2, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "k =  0 Prev Loss =  0.3837956488132477 Current Loss =  8.13695240020752\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  0 Prev Loss =  0.3837956488132477 Current Loss =  1.7003014087677002\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Prev Loss =  0.3837956488132477 Current Loss =  8.136640548706055\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Prev Loss =  0.3837956488132477 Current Loss =  8.1367826461792\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 28\n",
      "r_greedy =  [2, 1, 1, 2, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  1 Prev Loss =  0.020550517365336418 Current Loss =  0.3844512701034546\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  28\n",
      "numParam_greedy= 13\n",
      "k =  1 Prev Loss =  0.020550517365336418 Current Loss =  8.136846542358398\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  28\n",
      "numParam_greedy= 17\n",
      "k =  1 Prev Loss =  0.020550517365336418 Current Loss =  8.138627052307129\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  28\n",
      "numParam_greedy= 13\n",
      "k =  1 Prev Loss =  0.020550517365336418 Current Loss =  8.137307167053223\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  28\n",
      "numParam_greedy= 19\n",
      "k =  1 Prev Loss =  0.020550517365336418 Current Loss =  3.220580577850342\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  28\n",
      "numParam_greedy= 17\n",
      "k =  1 Prev Loss =  0.020550517365336418 Current Loss =  8.136693000793457\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  28\n",
      "numParam_greedy= 19\n",
      "k =  1 Prev Loss =  0.020550517365336418 Current Loss =  1.9323586225509644\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  28\n",
      "numParam_greedy= 17\n",
      "k =  1 Prev Loss =  0.020550517365336418 Current Loss =  8.13693618774414\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  28\n",
      "numParam_greedy= 17\n",
      "k =  1 Prev Loss =  0.020550517365336418 Current Loss =  8.136636734008789\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  28\n",
      "numParam_greedy= 37\n",
      "r_greedy =  [3, 1, 1, 2, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  2 Prev Loss =  0.004363940097391605 Current Loss =  0.3836359977722168\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  37\n",
      "numParam_greedy= 13\n",
      "k =  2 Prev Loss =  0.004363940097391605 Current Loss =  8.136777877807617\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  37\n",
      "numParam_greedy= 17\n",
      "k =  2 Prev Loss =  0.004363940097391605 Current Loss =  8.137300491333008\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  37\n",
      "numParam_greedy= 13\n",
      "k =  2 Prev Loss =  0.004363940097391605 Current Loss =  8.13696002960205\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  37\n",
      "numParam_greedy= 19\n",
      "k =  2 Prev Loss =  0.004363940097391605 Current Loss =  1.9341492652893066\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  37\n",
      "numParam_greedy= 17\n",
      "k =  2 Prev Loss =  0.004363940097391605 Current Loss =  8.136612892150879\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  37\n",
      "numParam_greedy= 19\n",
      "k =  2 Prev Loss =  0.004363940097391605 Current Loss =  1.9239742755889893\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  37\n",
      "numParam_greedy= 17\n",
      "k =  2 Prev Loss =  0.004363940097391605 Current Loss =  8.136834144592285\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  37\n",
      "numParam_greedy= 17\n",
      "k =  2 Prev Loss =  0.004363940097391605 Current Loss =  8.136788368225098\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  37\n",
      "numParam_greedy= 46\n",
      "r_greedy =  [4, 1, 1, 2, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  3 Prev Loss =  0.001709083328023553 Current Loss =  2.9009690284729004\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  46\n",
      "numParam_greedy= 13\n",
      "k =  3 Prev Loss =  0.001709083328023553 Current Loss =  8.136462211608887\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  46\n",
      "numParam_greedy= 17\n",
      "k =  3 Prev Loss =  0.001709083328023553 Current Loss =  8.13868236541748\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  46\n",
      "numParam_greedy= 13\n",
      "k =  3 Prev Loss =  0.001709083328023553 Current Loss =  8.137374877929688\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  46\n",
      "numParam_greedy= 19\n",
      "k =  3 Prev Loss =  0.001709083328023553 Current Loss =  5.638678073883057\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  46\n",
      "numParam_greedy= 17\n",
      "k =  3 Prev Loss =  0.001709083328023553 Current Loss =  8.137528419494629\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  46\n",
      "numParam_greedy= 19\n",
      "k =  3 Prev Loss =  0.001709083328023553 Current Loss =  1.7538812160491943\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  46\n",
      "numParam_greedy= 17\n",
      "k =  3 Prev Loss =  0.001709083328023553 Current Loss =  8.136878967285156\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  46\n",
      "numParam_greedy= 17\n",
      "k =  3 Prev Loss =  0.001709083328023553 Current Loss =  8.136371612548828\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  46\n",
      "numParam_greedy= 55\n",
      "r_greedy =  [5, 1, 1, 2, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  4 Prev Loss =  0.000998261384665966 Current Loss =  0.3947300612926483\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  55\n",
      "numParam_greedy= 13\n",
      "k =  4 Prev Loss =  0.000998261384665966 Current Loss =  8.136696815490723\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  55\n",
      "numParam_greedy= 17\n",
      "k =  4 Prev Loss =  0.000998261384665966 Current Loss =  8.137425422668457\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  55\n",
      "numParam_greedy= 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  4 Prev Loss =  0.000998261384665966 Current Loss =  8.137063026428223\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  55\n",
      "numParam_greedy= 19\n",
      "k =  4 Prev Loss =  0.000998261384665966 Current Loss =  6.680768966674805\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  55\n",
      "numParam_greedy= 17\n",
      "k =  4 Prev Loss =  0.000998261384665966 Current Loss =  8.13808536529541\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  55\n",
      "numParam_greedy= 19\n",
      "k =  4 Prev Loss =  0.000998261384665966 Current Loss =  2.155329942703247\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  55\n",
      "numParam_greedy= 17\n",
      "k =  4 Prev Loss =  0.000998261384665966 Current Loss =  8.136563301086426\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  55\n",
      "numParam_greedy= 17\n",
      "k =  4 Prev Loss =  0.000998261384665966 Current Loss =  8.137060165405273\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  55\n"
     ]
    }
   ],
   "source": [
    "############################### MAIN LOOP FOR GREEDY #####################\n",
    "\n",
    "#Initialize data\n",
    "iterNum=100   #500\n",
    "Lost_star = 1e12  #set it to be any large number\n",
    "check = 1\n",
    "maxParam = d1*d2*d3*d4\n",
    "numParam = -1\n",
    "paramKey = -1\n",
    "G = []\n",
    "\n",
    "for k in range(5):\n",
    "    if paramKey == 1:\n",
    "        break\n",
    "    for i in range(len(TensorList_temp)):\n",
    "        if paramKey == 1:\n",
    "            break\n",
    "        for j in range(i,len(TensorList_temp)):\n",
    "            if paramKey == 1:\n",
    "                break\n",
    "            if i==j:\n",
    "                continue\n",
    "            #print(i,j)\n",
    "            #increase the ranks of the tensors\n",
    "            [TensorList_temp[i],TensorList_temp[j]] = increaseRank(TensorList_temp[i], TensorList_temp[j],  indxList[i], indxList[j])            \n",
    "            #check num of paramters for the newly updated ranks\n",
    "           # rt = list of ranks: [r1_t,r2_t,r3_t,r4_t,r5_t,r6_t,r7_t,r8_t]\n",
    "            rt = printRank(TensorList_temp)\n",
    "            numParam_temp = getNumParams(rt)\n",
    "            print('numParam_greedy=', numParam_temp)\n",
    "            if numParam_temp > maxParam:\n",
    "                paramKey = 1\n",
    "                print('Max number of parameters exceeded. Current Param = ', numParam_temp, 'and max Param allowed = ', maxParam)\n",
    "                print('program finish ')\n",
    "                break\n",
    "            #solve continuous part\n",
    "            [TensorList_temp, indxList, LostList] = solve_Continuous(target_Tensor, TensorList_temp, indxList, iterNum)\n",
    "            printRank(TensorList_temp)\n",
    "            #store the optimal value for a given point around its neighbour\n",
    "            if Lost_star > LostList[-1]: \n",
    "                    indx_star = [i,j]\n",
    "                    TensorList_star = TensorList_temp[:]\n",
    "                    indxList_star = indxList[:]  \n",
    "                    Lost_star = LostList[-1]  \n",
    "                    r_greedy = printRank(TensorList_star)\n",
    "                    print('r_greedy = ', r_greedy)\n",
    "                    numParam = getNumParams(r_greedy )\n",
    "                    check = -1\n",
    "            elif Lost_star <= LostList[-1]:\n",
    "                print('k = ', k, 'Prev Loss = ', Lost_star, 'Current Loss = ', LostList[-1])\n",
    "                print('Loss previous is less than current, so no rank update is made at this iteration')\n",
    "                print('total number of parameters for best chosen rank = ', numParam)\n",
    "         \n",
    "            #Reset TensorList_temp to continue with greedy at another point\n",
    "            TensorList_temp = TensorList[:] #set back to previous position to continue with greedy search        \n",
    "    #update parameters   \n",
    "    TensorList_temp = TensorList_star[:]    #everything is behaving as expected\n",
    "    indxList = indxList_star[:]     # don't really need to update this cause these don't really change\n",
    "    TensorList_greedy   = TensorList_star[:]  #everything is behaving as expected\n",
    "    G.append(Lost_star)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tapprox_greedy.shape =  torch.Size([3, 3, 3, 3])\n",
      "len(yi_approxSet_greedy) =  7\n"
     ]
    }
   ],
   "source": [
    "#GREEDY script continue\n",
    "#TensorList contains decomposed block of tensors. We use einsum to combine them into one \n",
    "#big tensor Tapprox_greedy\n",
    "Tapprox_greedy = einSum_Contraction(TensorList_greedy, indxList)  #TensorList_Greedy = TensorList\n",
    "print('Tapprox_greedy.shape = ', Tapprox_greedy.shape)\n",
    "\n",
    "#generate yi_approx = tensorApprox_star * X_i. Plot this set of yi_approx, with yi\n",
    "indxlist_greedy = ['abcd', 'abcd']   # abcd =  = d1*d2*d3*d4 i.e. each alphabet represents each dimension ot target tensor\n",
    "yi_approxSet_greedy = getYi_set(Xi_test, Tapprox_greedy, indxlist_greedy)\n",
    "print('len(yi_approxSet_greedy) = ', len(yi_approxSet_greedy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFUhJREFUeJzt3X/sXfV93/HnqwYTq8kKLV9pwT9i0zqopulweutkQqVV\nG2KnqWzUUcWRspEtk5UuVjaxsJqlGpqjqSlIWbXNFXgrUpaVOTRD6LusyCIl6VRpEF/HJNQwL1+c\nNHxxJFzMj02xAJP3/vgep5cvX/uea399r+3zfEhX3PM5n8+97/sx9/U995x77klVIUnqhh+bdAGS\npPEx9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqkFahn2RTkkNJZpLsOE2/m5NUkt5A2+3NuENJ\nNi5G0ZKkM3PJsA5JlgC7gBuBWWBfkumqenJev7cBnwQeG2hbB2wFrgWuAr6S5J1V9frivQRJUltD\nQx/YAMxU1WGAJHuALcCT8/p9BrgT+NRA2xZgT1W9AnwnyUzzeP/rVE925ZVX1urVq1u/AEkS7N+/\n/6+rampYvzahvxx4ZmB5FnjPYIck64GVVfXlJJ+aN/bReWOXn+7JVq9eTb/fb1GWJOmkJH/Vpl+b\nffpZoO1HP9iT5MeAfwv881HHDjzGtiT9JP2jR4+2KEmSdCbahP4ssHJgeQVwZGD5bcDPAV9L8l3g\nvcB0czB32FgAqmp3VfWqqjc1NfTTiSTpDLUJ/X3A2iRrkixl7sDs9MmVVfVSVV1ZVaurajVzu3M2\nV1W/6bc1yWVJ1gBrga8v+quQJLUydJ9+VZ1Ish3YCywB7q2qg0l2Av2qmj7N2INJ7mfuoO8J4BN+\nc0eSJifn2+/p93q98kCuJI0myf6q6g3r1+bbOxeEBw88y117D3HkxeNcdfkybtt4DTetP+0XhSSp\ncy6K0H/wwLPc/sATHH9tbs/Rsy8e5/YHngAw+CVpwEXx2zt37T30o8A/6fhrr3PX3kMTqkiSzk8X\nRegfefH4SO2S1FUXRehfdfmykdolqasuitC/beM1LLt0yRvall26hNs2XjOhiiTp/HRRHMg9ebDW\nb+9I0uldFKEPc8FvyEvS6V0Uu3ckSe0Y+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i\n6EtSh7QK/SSbkhxKMpNkxwLrP57kiSSPJ/mLJOua9tVJjjftjye5e7FfgCSpvaE/w5BkCbALuBGY\nBfYlma6qJwe63VdVdzf9NwOfAzY1656uqusWt2xJ0plos6W/AZipqsNV9SqwB9gy2KGqXh5Y/HHg\n/LrwriQJaBf6y4FnBpZnm7Y3SPKJJE8DdwKfHFi1JsmBJH+e5JfOqlpJ0llpE/pZoO1NW/JVtauq\nfhr4HeB3m+bvA6uqaj1wK3Bfkr/1pidItiXpJ+kfPXq0ffWSpJG0Cf1ZYOXA8grgyGn67wFuAqiq\nV6rq+eb+fuBp4J3zB1TV7qrqVVVvamqqbe2SpBG1Cf19wNoka5IsBbYC04MdkqwdWPwg8O2mfao5\nEEySq4G1wOHFKFySNLqh396pqhNJtgN7gSXAvVV1MMlOoF9V08D2JO8DXgNeAG5pht8A7ExyAngd\n+HhVHTsXL0SSNFyqzq8v2vR6ver3+5MuQ5IuKEn2V1VvWD/PyJWkDjH0JalDDH1J6hBDX5I6xNCX\npA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCX\npA5pFfpJNiU5lGQmyY4F1n88yRNJHk/yF0nWDay7vRl3KMnGxSxekjSaoaHfXNh8F/ABYB3w4cFQ\nb9xXVe+qquuAO4HPNWPXMXch9WuBTcAfnrxQuiRp/Nps6W8AZqrqcFW9CuwBtgx2qKqXBxZ/HDh5\n4d0twJ6qeqWqvgPMNI8nSZqAS1r0WQ48M7A8C7xnfqcknwBuBZYCvzow9tF5Y5efUaWSpLPWZks/\nC7TVmxqqdlXVTwO/A/zuKGOTbEvST9I/evRoi5IkSWeiTejPAisHllcAR07Tfw9w0yhjq2p3VfWq\nqjc1NdWiJEnSmWgT+vuAtUnWJFnK3IHZ6cEOSdYOLH4Q+HZzfxrYmuSyJGuAtcDXz75sSdKZGLpP\nv6pOJNkO7AWWAPdW1cEkO4F+VU0D25O8D3gNeAG4pRl7MMn9wJPACeATVfX6OXotkqQhUvWmXewT\n1ev1qt/vT7oMSbqgJNlfVb1h/TwjV5I6xNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnq\nEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOqRV6CfZlORQkpkkOxZY\nf2uSJ5N8K8mfJXnHwLrXkzze3Kbnj5Ukjc/Qa+QmWQLsAm4EZoF9Saar6smBbgeAXlX9IMlvA3cC\nH2rWHa+q6xa5bknSGWizpb8BmKmqw1X1KrAH2DLYoaq+WlU/aBYfBVYsbpmSpMXQJvSXA88MLM82\nbafyMeChgeW3JOkneTTJTQsNSLKt6dM/evRoi5IkSWdi6O4dIAu01YIdk48APeCXB5pXVdWRJFcD\njyR5oqqefsODVe0GdgP0er0FH1uSdPbabOnPAisHllcAR+Z3SvI+4NPA5qp65WR7VR1p/nsY+Bqw\n/izqlSSdhTahvw9Ym2RNkqXAVuAN38JJsh64h7nAf26g/YoklzX3rwSuBwYPAEuSxmjo7p2qOpFk\nO7AXWALcW1UHk+wE+lU1DdwFvBX4kyQA36uqzcDPAvck+SFzf2A+O+9bP5KkMUrV+bULvdfrVb/f\nn3QZknRBSbK/qnrD+nlGriR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWI\noS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhrUI/yaYkh5LMJNmxwPpbkzyZ5FtJ/izJ\nOwbW3ZLk283tlsUsXpI0mqGhn2QJsAv4ALAO+HCSdfO6HQB6VfXzwJeAO5uxPwncAbwH2ADckeSK\nxStfkjSKNlv6G4CZqjpcVa8Ce4Atgx2q6qtV9YNm8VFgRXN/I/BwVR2rqheAh4FNi1O6JGlUbUJ/\nOfDMwPJs03YqHwMeOsOxkqRz6JIWfbJA24JXU0/yEaAH/PIoY5NsA7YBrFq1qkVJkqQz0WZLfxZY\nObC8Ajgyv1OS9wGfBjZX1SujjK2q3VXVq6re1NRU29olSSNqE/r7gLVJ1iRZCmwFpgc7JFkP3MNc\n4D83sGov8P4kVzQHcN/ftEmSJmDo7p2qOpFkO3NhvQS4t6oOJtkJ9KtqGrgLeCvwJ0kAvldVm6vq\nWJLPMPeHA2BnVR07J69EkjRUqhbcPT8xvV6v+v3+pMuQpAtKkv1V1RvWzzNyJalDDH1J6hBDX5I6\nxNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6\nxNCXpA4x9CWpQ1qFfpJNSQ4lmUmyY4H1NyT5RpITSW6et+71JI83t+n5YyVJ4zP0GrlJlgC7gBuB\nWWBfkumqenKg2/eAjwKfWuAhjlfVdYtQqyTpLA0NfWADMFNVhwGS7AG2AD8K/ar6brPuh+egRknS\nImmze2c58MzA8mzT1tZbkvSTPJrkppGqkyQtqjZb+lmgrUZ4jlVVdSTJ1cAjSZ6oqqff8ATJNmAb\nwKpVq0Z4aEnSKNps6c8CKweWVwBH2j5BVR1p/nsY+BqwfoE+u6uqV1W9qamptg8tSRpRm9DfB6xN\nsibJUmAr0OpbOEmuSHJZc/9K4HoGjgVIksZraOhX1QlgO7AXeAq4v6oOJtmZZDNAkl9MMgv8FnBP\nkoPN8J8F+km+CXwV+Oy8b/1IksYoVaPsnj/3er1e9fv9SZchSReUJPurqjesn2fkSlKHGPqS1CGG\nviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGG\nviR1iKEvSR1i6EtSh7QK/SSbkhxKMpNkxwLrb0jyjSQnktw8b90tSb7d3G5ZrMIlSaMbGvpJlgC7\ngA8A64APJ1k3r9v3gI8C980b+5PAHcB7gA3AHUmuOPuyJUlnos2W/gZgpqoOV9WrwB5gy2CHqvpu\nVX0L+OG8sRuBh6vqWFW9ADwMbFqEuiVJZ6BN6C8HnhlYnm3a2jibsZKkRdYm9LNAW7V8/FZjk2xL\n0k/SP3r0aMuHliSNqk3ozwIrB5ZXAEdaPn6rsVW1u6p6VdWbmppq+dCSpFG1Cf19wNoka5IsBbYC\n0y0ffy/w/iRXNAdw39+0SZImYGjoV9UJYDtzYf0UcH9VHUyyM8lmgCS/mGQW+C3gniQHm7HHgM8w\n94djH7CzaZMkTUCq2u6eH49er1f9fn/SZUjSBSXJ/qrqDevnGbmS1CGGviR1iKEvSR1i6EtShxj6\nktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6\nktQhrUI/yaYkh5LMJNmxwPrLknyxWf9YktVN++okx5M83tzuXtzyJUmjuGRYhyRLgF3AjcAssC/J\ndFU9OdDtY8ALVfUzSbYCvw98qFn3dFVdt8h1S5LOQJst/Q3ATFUdrqpXgT3Alnl9tgCfb+5/Cfi1\nJFm8MiVJi6FN6C8HnhlYnm3aFuxTVSeAl4CfatatSXIgyZ8n+aWzrFeSdBaG7t4BFtpir5Z9vg+s\nqqrnk/wC8GCSa6vq5TcMTrYB2wBWrVrVoiRJ0plos6U/C6wcWF4BHDlVnySXAD8BHKuqV6rqeYCq\n2g88Dbxz/hNU1e6q6lVVb2pqavRXIUlqpU3o7wPWJlmTZCmwFZie12cauKW5fzPwSFVVkqnmQDBJ\nrgbWAocXp3RJ0qiG7t6pqhNJtgN7gSXAvVV1MMlOoF9V08AfAV9IMgMcY+4PA8ANwM4kJ4DXgY9X\n1bFz8UIkScOlav7u+cnq9XrV7/cnXYYkXVCS7K+q3rB+npErSR1i6EtShxj6ktQhhr4kdYihL0kd\nYuhLUocY+pLUIW1+e0cXoQcPPMtdew9x5MXjXHX5Mm7beA03rZ//O3qSLjaGfgc9eOBZbn/gCY6/\n9joAz754nNsfeALA4Jcucu7e6aC79h76UeCfdPy117lr76EJVSRpXAz9Djry4vGR2iVdPAz9Drrq\n8mUjtUu6eBj6HXTbxmtYdumSN7Qtu3QJt228ZkIVSRoXD+R20MmDtX57R+oeQ7+jblq/3JCXOsjQ\nl1rwvAZdLAx9aQjPa9DFpNWB3CSbkhxKMpNkxwLrL0vyxWb9Y0lWD6y7vWk/lGTj4pUujYfnNYzu\nwQPPcv1nH2HNjv/B9Z99hAcPPDvpks5r45yvoVv6zYXNdwE3ArPAviTTVfXkQLePAS9U1c8k2Qr8\nPvChJOuYu17utcBVwFeSvLOq3vgOks5jntcwGj8ZjWbc89VmS38DMFNVh6vqVWAPsGVeny3A55v7\nXwJ+LUma9j1V9UpVfQeYaR5PumB4XsNo/GQ0mnHPV5vQXw48M7A827Qt2KeqTgAvAT/VcixJtiXp\nJ+kfPXq0ffXSGHhew2j8ZDSacc9Xm9DPAm3Vsk+bsVTV7qrqVVVvamqqRUnS+Ny0fjm/95vvYvnl\nywiw/PJl/N5vvstdFafgJ6PRjHu+2nx7ZxZYObC8Ajhyij6zSS4BfgI41nKsdN7zvIb2btt4zRv2\nUYOfjE5n3PPVZkt/H7A2yZokS5k7MDs9r880cEtz/2bgkaqqpn1r8+2eNcBa4OuLU7qk85GfjEYz\n7vnKXDYP6ZT8OvAHwBLg3qr6N0l2Av2qmk7yFuALwHrmtvC3VtXhZuyngX8EnAD+WVU9dLrn6vV6\n1e/3z+Y1SVLnJNlfVb2h/dqE/jgZ+pI0urah769sSlKHGPqS1CGGviR1iKEvSR1y3h3ITXIU+Kuz\neIgrgb9epHIWk3WNxrpGY12juRjrekdVDT279bwL/bOVpN/mCPa4WddorGs01jWaLtfl7h1J6hBD\nX5I65GIM/d2TLuAUrGs01jUa6xpNZ+u66PbpS5JO7WLc0pckncIFGfpnc83eCdf10SRHkzze3P7x\nmOq6N8lzSf7yFOuT5N81dX8rybvPk7p+JclLA/P1r8ZU18okX03yVJKDSf7pAn3GPmct6xr7nCV5\nS5KvJ/lmU9e/XqDP2N+TLeuayHuyee4lSQ4k+fIC687dfFXVBXVj7pc+nwauBpYC3wTWzevzT4C7\nm/tbgS+eJ3V9FPgPE5izG4B3A395ivW/DjzE3EVv3gs8dp7U9SvAlycwX28H3t3cfxvwfxb4txz7\nnLWsa+xz1szBW5v7lwKPAe+d12cS78k2dU3kPdk8963AfQv9e53L+boQt/TP5pq9k65rIqrqfzL3\nk9ensgX4zzXnUeDyJG8/D+qaiKr6flV9o7n/f4GnePNlPsc+Zy3rGrtmDv5fs3hpc5t/sHDs78mW\ndU1EkhXAB4H/dIou52y+LsTQP5tr9k66LoC/1+wO+FKSlQusn4S2tU/C320+nj+U5NpxP3nzsXo9\nc1uJgyY6Z6epCyYwZ82uiseB54CHq+qU8zXG92SbumAy78k/AP4F8MNTrD9n83Uhhv7ZXLP3XGrz\nnP8dWF1VPw98hb/5Sz5pk5ivNr7B3Knlfwf498CD43zyJG8F/htzF/95ef7qBYaMZc6G1DWROauq\n16vqOuYuibohyc/N6zKR+WpR19jfk0l+A3iuqvafrtsCbYsyXxdi6I9yzV7yxmv2TrSuqnq+ql5p\nFv8j8AvnuKa2zstrGVfVyyc/nlfVnwKXJrlyHM+d5FLmgvWPq+qBBbpMZM6G1TXJOWue80Xga8Cm\neasm8Z4cWteE3pPXA5uTfJe53cC/muS/zOtzzubrQgz9s7lm70TrmrfPdzNz+2TPB9PAP2i+kfJe\n4KWq+v6ki0ryt0/ux0yygbn/X58fw/MG+CPgqar63Cm6jX3O2tQ1iTlLMpXk8ub+MuB9wP+e123s\n78k2dU3iPVlVt1fViqpazVxOPFJVH5nX7ZzN1yWL8SDjVFUnkmwH9vI31+w9mIFr9jL3xvhCkhma\na/aeJ3V9Mslm5q4XfIy5bw6cc0n+K3Pf6rgyySxwB3MHtaiqu4E/Ze7bKDPAD4B/eJ7UdTPw20lO\nAMeZu/byOHahXA/8feCJZn8wwL8EVg3UNok5a1PXJObs7cDnkyxh7o/M/VX15Um/J1vWNZH35ELG\nNV+ekStJHXIh7t6RJJ0hQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalD/j+96V+hFXsK\nVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ecf4c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy: G =  [0.3837956488132477, 0.020550517365336418, 0.004363940097391605, 0.001709083328023553, 0.000998261384665966]\n"
     ]
    }
   ],
   "source": [
    " # plot for all the greedy loops\n",
    "    #import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(G, 'o')\n",
    "plt.show()\n",
    "print('greedy: G = ', G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Method: best rank r =  [1, 2, 2, 2, 1, 2, 1, 4] with loss =  221.47479248046875\n"
     ]
    }
   ],
   "source": [
    "#***********************STOCHASTIC APPROACH MAIN******************************************\n",
    "\n",
    "#The following main program assigns random values to each of the 8 ranks and computes the continuos optimization\n",
    "#part. It repeats 8 times (8 trials) and selects the trial with the smallest lost.\n",
    "\n",
    "#initilize data\n",
    "iterNum=100   #500\n",
    "maxParam = d1*d2*d3*d4\n",
    "#print('maxParam = ', maxParam) \n",
    "L = []\n",
    "#generate sequence of random ranks between 1 to 8\n",
    "numRank = 8\n",
    "d=4  #highest dimension you want to explore\n",
    "max_numShots = 15  #number of random trials you want to perform\n",
    "dmax = max(d1,d2,d3,d4)\n",
    "numShots = 0\n",
    "LostList_prev = 1e12\n",
    "\n",
    "#for i in range(numShots):\n",
    "while numShots <max_numShots:\n",
    "    r_stoch = get_RandomSeqence(numRank,d)\n",
    "    #initialize tensor \n",
    "    A_0 = torch.rand(r_stoch[1],d1,r_stoch[0],r_stoch[6])\n",
    "    B_0 = torch.rand(r_stoch[0],d2,r_stoch[3],r_stoch[7])\n",
    "    C_0 = torch.rand(r_stoch[1],d3,r_stoch[2],r_stoch[5])\n",
    "    D_0 = torch.rand(r_stoch[3],d4,r_stoch[2],r_stoch[4]) \n",
    "    G_0 = torch.rand(r_stoch[4],r_stoch[5],r_stoch[6],r_stoch[7])\n",
    "    TensorList_temp = [A_0,B_0,C_0,D_0,G_0] #TensorList[:]   \n",
    "    #the following if loop checks the number of elements of each A_0, ..., G_0\n",
    "    #does not exceed the total number elements of target tensor\n",
    "    #numParamList = getNumParams(r_stoch)\n",
    "    #if maxParam > numParamList[0] and maxParam > numParamList[1] and maxParam > numParamList[2] and maxParam > numParamList[3] and maxParam > numParamList[4]:\n",
    "    if maxParam > getNumParams(r_stoch):\n",
    "        [TensorList_temp, indxList, LostList] = solve_Continuous(target_Tensor, TensorList_temp, indxList, iterNum)\n",
    "        L.append(LostList[-1])\n",
    "        numShots += 1\n",
    "        #the following if-loop stores the approx tensor that gives the smallest loss\n",
    "        if LostList[-1] <LostList_prev:\n",
    "            tensorApprox_star = TensorList_temp[:]\n",
    "            LostList_prev = LostList[-1]\n",
    "            r_Star = r_stoch       \n",
    "print('Stochastic Method: best rank r = ', r_Star, 'with loss = ', LostList_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#...STOCHASTIC SCRIPT CONTINUE\n",
    "#tensorApprox_star consists of blocks of tensor. We take tensor product of all these\n",
    "#blocks to get one big block: TensorApprox_Stoch\n",
    "indxList = [indxA, indxB, indxC, indxD, indxG]  #use the exact same indxList as the ones above\n",
    "TensorApprox_Stoch = einSum_Contraction([tensorApprox_star[0],tensorApprox_star[1],tensorApprox_star[2],tensorApprox_star[3],tensorApprox_star[4]], [indxA, indxB, indxC, indxD, indxG])\n",
    "\n",
    "#generate yi_approx = tensorApprox_star * X_i. \n",
    "indxlist_stoch = [indx, indx]   # indx_Xi = indx_W = indx. \n",
    "yi_approxSet_stoch = getYi_set(Xi_test, TensorApprox_Stoch, indxlist_stoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_RW = [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "nextDirection =  5\n",
      "r_RW = [1, 1, 1, 1, 1, 2, 1, 1]\n",
      "nextDirection =  0\n",
      "r_RW = [2, 1, 1, 1, 1, 2, 1, 1]\n",
      "nextDirection =  5\n",
      "r_RW = [2, 1, 1, 1, 1, 3, 1, 1]\n",
      "nextDirection =  4\n",
      "r_RW = [2, 1, 1, 1, 2, 3, 1, 1]\n",
      "nextDirection =  6\n",
      "r_RW = [2, 1, 1, 1, 2, 3, 2, 1]\n",
      "nextDirection =  0\n",
      "r_RW = [3, 1, 1, 1, 2, 3, 2, 1]\n",
      "nextDirection =  5\n",
      "r_RW = [3, 1, 1, 1, 2, 4, 2, 1]\n",
      "nextDirection =  7\n",
      "Random Walk: numParam =  86 maxNumParam of target tensor =  81\n",
      "G_RW =  [9984.0439453125, 6356.84033203125, 2429.841796875, 2011.295166015625, 1716.7403564453125, 1679.0604248046875, 622.0523071289062]\n"
     ]
    }
   ],
   "source": [
    "#################################Random Walk(RW) main###############################\n",
    "maxParam = d1*d2*d3*d4\n",
    "iterNum = 100\n",
    "#initialize the edges to 1\n",
    "r_RW = [1,1,1,1,1,1,1,1]\n",
    "numParam_RW = getNumParams(r_RW)\n",
    "Lost_starRW = 1e12  #set it to be any large number\n",
    "G_RW = []\n",
    "while maxParam > numParam_RW:\n",
    "    print('r_RW =', r_RW)\n",
    "    r_RW = get_Next_randomEdge(r_RW)\n",
    "    numParam_RW = getNumParams(r_RW)\n",
    "    #initialize tensor \n",
    "    if maxParam > numParam_RW:\n",
    "        A_0 = torch.rand(r_RW[1],d1,r_RW[0],r_RW[6])\n",
    "        B_0 = torch.rand(r_RW[0],d2,r_RW[3],r_RW[7])\n",
    "        C_0 = torch.rand(r_RW[1],d3,r_RW[2],r_RW[5])\n",
    "        D_0 = torch.rand(r_RW[3],d4,r_RW[2],r_RW[4]) \n",
    "        G_0 = torch.rand(r_RW[4],r_RW[5],r_RW[6],r_RW[7])\n",
    "        TensorList_RW = [A_0,B_0,C_0,D_0,G_0]\n",
    "        [TensorList_RW, indxList, LostList_RW] = solve_Continuous(target_Tensor, TensorList_RW, indxList, iterNum)\n",
    "        G_RW.append(LostList_RW[-1])\n",
    "\n",
    "print('Random Walk: numParam = ', numParam_RW, 'maxNumParam of target tensor = ', maxParam)\n",
    "print('G_RW = ', G_RW)\n",
    "\n",
    "#take the block tensors and combine them to form 1 big tensor: TensorApprox_RW \n",
    "indxList = [indxA, indxB, indxC, indxD, indxG]  #use the exact same indxList as the ones above\n",
    "TensorApprox_RW = einSum_Contraction([TensorList_RW[0], TensorList_RW[1], TensorList_RW[2], TensorList_RW[3], TensorList_RW[4]], [indxA, indxB, indxC, indxD, indxG])\n",
    "indxlist_RW = ['abcd', 'abcd']   # abcd =  = d1*d2*d3*d4 i.e. each alphabet represents each dimension ot target tensor\n",
    "yi_approxSet_RW = getYi_set(Xi_test, TensorApprox_RW, indxlist_RW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12eada5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##PLOT FOR RANDOM WALK. X-AXIS = total number of steps and Y-axis = LostList[-1]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(G_RW, 'og')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e9a1b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend\n",
      "red: actual data\n",
      "green: predicted data using stochastic\n",
      "blue: predicted data using greedy\n",
      "magenta: predicted data using random walk\n"
     ]
    }
   ],
   "source": [
    "#we assume yi_actual = yi_train. \n",
    "#The following plot compares the approx yi using different the 3 different approach (greedy, stochastic, random walk)\n",
    "# and compare the approx to the actual data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(yi_approxSet_stoch, 'og')\n",
    "plt.plot(yi_approxSet_greedy, 'ob')\n",
    "plt.plot(yi_approxSet_RW, 'om')\n",
    "plt.plot(yi_test, '*r')   #recall we treat yi_test as our true data\n",
    "plt.title('Greedy, stochastic, randomWalk data vs actual data ',loc='center')\n",
    "plt.show()\n",
    "\n",
    "print('Legend')\n",
    "print('red: actual data')\n",
    "print('green: predicted data using stochastic')\n",
    "print('blue: predicted data using greedy')\n",
    "print('magenta: predicted data using random walk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_stoch =  770.2573320784259\n",
      "RMSE_greedy =  14.378347850711158\n",
      "RMSE_randomWalk =  89.64448568905128\n"
     ]
    }
   ],
   "source": [
    "# Compute RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "RMSE_stoch = sqrt(mean_squared_error(yi_test,yi_approxSet))\n",
    "print('RMSE_stoch = ',RMSE_stoch)\n",
    "\n",
    "RMSE_greedy = sqrt(mean_squared_error(yi_test,yi_approxSet_greedy))\n",
    "print('RMSE_greedy = ',RMSE_greedy) \n",
    "\n",
    "RMSE_RW = sqrt(mean_squared_error(yi_test,yi_approxSet_RW))\n",
    "print('RMSE_randomWalk = ',RMSE_RW) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stoch Method: % rel. error =  tensor(15.9501, grad_fn=<MulBackward0>)\n",
      "Greedy Method: % rel. error =  tensor(5.1030, grad_fn=<MulBackward0>)\n",
      "Random Walk Method: % rel. error =  tensor(27.7737, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#relative error\n",
    "def getRelError(yi_actual,yi_pred):\n",
    "# Both yi_actual,yi_pred are a set of elements\n",
    "    summ = 0\n",
    "    nm = 0\n",
    "    N = len(yi_actual)\n",
    "    for i in range(N):\n",
    "        summ = summ + abs(yi_actual[i] - yi_pred[i])\n",
    "        nm = nm + abs(yi_actual[i])\n",
    "    return summ/nm*100 \n",
    "\n",
    "RE_stoch = getRelError(yi_test,yi_approxSet_stoch)\n",
    "print('stoch Method: % rel. error = ', RE_stoch)\n",
    "\n",
    "RE_greedy = getRelError(yi_test,yi_approxSet_greedy)\n",
    "print('Greedy Method: % rel. error = ', RE_greedy)\n",
    "\n",
    "RE_RW = getRelError(yi_test,yi_approxSet_RW)\n",
    "print('Random Walk Method: % rel. error = ', RE_RW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
