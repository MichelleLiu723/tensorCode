{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see notes in blue binder for documents of this. \n",
    "#code was tested on three tensors: A-B-C\n",
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('..')\n",
    "from core_code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 3, 3])\n",
      "torch.Size([3, 2, 4])\n",
      "shapeTargetTensor= torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Add function to core_code that initializes a random tensor with\n",
    "#       prescribed input dimensions and ranks\n",
    "\n",
    "#generate target tensor of rank 1\n",
    "X =  torch.Tensor([[[1]],[[2]]])\n",
    "Y =  torch.Tensor([[[3],[4],[5]]])\n",
    "Z =  torch.Tensor([[[6,7,8,9]]])\n",
    "\n",
    "d1 = 2\n",
    "d2 = 3\n",
    "d3 = 4\n",
    "r1 = 2\n",
    "r2 = 3\n",
    "r3 = 2\n",
    "\n",
    "X = torch.rand(d1, r3, r1)\n",
    "Y = torch.rand(r1, d2, r2)\n",
    "Z = torch.rand(r2, r3, d3)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Z.shape)\n",
    "\n",
    "indx0 = 'ijk'\n",
    "indx1 = 'klm'\n",
    "indx2 = 'mjp'\n",
    "\n",
    "target_Tensor = einSum_Contraction([X, Y, Z], [indx0, indx1, indx2])\n",
    "print('shapeTargetTensor=', target_Tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the function mentioned in the above cell to initialize our tensor network\n",
    "\n",
    "#initilize\n",
    "r1 = 1\n",
    "r2 = 1\n",
    "r3 = 1\n",
    "#generate at random target tensor\n",
    "X_approx0 = torch.rand(d1,r3,r1)*1\n",
    "X_approx0 = X_approx0/torch.norm(X_approx0, 'fro') \n",
    "Y_approx0 = torch.rand(r1,d2,r2)*1\n",
    "Y_approx0 = Y_approx0/torch.norm(Y_approx0, 'fro') \n",
    "Z_approx0 = torch.rand(r2,r3,d3)*1\n",
    "Z_approx0 = Z_approx0/torch.norm(Z_approx0, 'fro') \n",
    "\n",
    "##this intialize tensor close to target tensor. This is to confirm the loss function is low as eplected\n",
    "#noise = 0.000000000001\n",
    "#X_approx0 =  torch.Tensor([[[1]],[[2]]]) + torch.rand(2,1,1)*noise  #need to check it is from normal distribution\n",
    "#Y_approx0 =  torch.Tensor([[[3],[4],[5]]])+ torch.rand(1,3,1)*noise\n",
    "#Z_approx0 =  torch.Tensor([[[6,7,8,9]]])+ torch.rand(1,1,4)*noise\n",
    "\n",
    "indx0 = 'ijk'\n",
    "indx1 = 'kmn'\n",
    "indx2 = 'njp'\n",
    "indxList = [indx0, indx1, indx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for the experiment (anything you want to feed to the Pytorch optimizer)\n",
    "hyperparams = {'lr': 0.009,\n",
    "               'some_other_param': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-50bf4e41b45b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m#check num of paramters for the newly updated ranks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mr1_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr2_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr3_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprintRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorList_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mnumParam_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNumParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr2_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr3_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num of parameters for recently updated ranks= '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumParam_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorCode/core_code.py\u001b[0m in \u001b[0;36mprintRank\u001b[0;34m(TensorList)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;31m#       tensor network, not just for 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprintRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mr5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr8\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTensorList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tensor G dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mr4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTensorList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tensor D dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr7\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTensorList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tensor A dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# TODO: Package up code for the greedy optimization loop into a standalone function\n",
    "#       in core_tools, where the loss function and target data (among other things) \n",
    "#       are inputs\n",
    "\n",
    "#Here we added a third loop. Each iteration samples a different grid point and its nearby neighbours. It computes the continuous\n",
    "#opt for different rank combinations and stores the one with the least minimum.\n",
    "A = X_approx0\n",
    "B = Y_approx0\n",
    "C = Z_approx0\n",
    "\n",
    "indxList = [indx0, indx1, indx2]\n",
    "TensorList = [A, B, C]\n",
    "TensorList_temp = [A, B, C] #TensorList[:]\n",
    "iterNum=500\n",
    "Lost_star = 5\n",
    "check = 1\n",
    "maxParam = d1*d2*d3\n",
    "numParam = -1\n",
    "paramKey = -1\n",
    "\n",
    "for k in range(5):\n",
    "    if paramKey == 1:\n",
    "        break\n",
    "    for i in range(len(TensorList_temp)):\n",
    "        if paramKey == 1:\n",
    "            break\n",
    "        for j in range(i+1,len(TensorList_temp)):\n",
    "            if paramKey == 1:\n",
    "                break\n",
    "            print(i,j)\n",
    "            #increase the ranks of the tensors\n",
    "            [TensorList_temp[i],TensorList_temp[j]] = increaseRank(TensorList_temp[i], TensorList_temp[j],  indxList[i], indxList[j])\n",
    "            \n",
    "            #check num of paramters for the newly updated ranks\n",
    "            [r1_t,r2_t,r3_t] = printRank(TensorList_temp)\n",
    "            numParam_temp = getNumParams(r1_t,r2_t,r3_t)\n",
    "            print('num of parameters for recently updated ranks= ', numParam_temp)\n",
    "            if numParam_temp > maxParam:\n",
    "                paramKey = 1\n",
    "                print('Max number of parameters exceeded. Current Param = ', numParam_temp, 'and max Param allowed = ', maxParam)\n",
    "                print('program finish ')\n",
    "                break\n",
    "            #solve continuous part\n",
    "            [TensorList_temp, indxList, LostList] = solve_Continuous(target_Tensor, TensorList_temp, indxList, iterNum, \n",
    "                                                                     computeLoss_Factorization, hyperparams)\n",
    "            print('Currently evaluating rank:')\n",
    "            printRank(TensorList_temp)\n",
    "            \n",
    "            #store the optimal value for a given point around its neighbour\n",
    "            if Lost_star > LostList[-1]: #avgLost:  #When have time, take the average of 10 elements as opposed to the min. of last elementLostList[-1]:  #When have time, take the average of 10 elements as opposed to the min. of last element\n",
    "                    indx_star = [i,j]\n",
    "                    TensorList_star = TensorList_temp[:]\n",
    "                    indxList_star = indxList[:]\n",
    "                    print('Lost* updated: Lost_star previous =', Lost_star, 'Lost_star current =', LostList[-1])\n",
    "                    Lost_star = LostList[-1]  \n",
    "                    print('current Best rank:')\n",
    "                    [r1,r2,r3] = printRank(TensorList_star)\n",
    "                    numParam = getNumParams(r1,r2,r3)\n",
    "                    #numParam = d1*r1*r3 + r1*d2*r2 + r2*r3*d3\n",
    "                    #print('d1*r1*r3 = ', d1*r1*r3)\n",
    "                    #print('r1*d2*r2', r1*d2*r2)\n",
    "                    #print('r2*r3*d3', r2*r3*d3)\n",
    "                    print('total number of parameters for best chosen ranks = ', numParam)\n",
    "                    check = -1\n",
    "            elif Lost_star <= LostList[-1]:\n",
    "                print('Prev Loss = ', Lost_star, 'Current Loss = ', LostList[-1])\n",
    "                print('Loss previous is less than current, so no rank update is made at this iteration')\n",
    "                print('total number of parameters for best chosen rank = ', numParam)\n",
    "\n",
    "            \n",
    "            #Reset TensorList_temp to continue with greedy at another point\n",
    "            TensorList_temp = TensorList[:] #set back to previous position to continue with greedy search\n",
    "            print('***************************************************************')  \n",
    "    print('****************************moving to another grid point ***********************************')\n",
    "    #update parameters   \n",
    "    #print('TensorList_star[0] = ', TensorList_star[0])\n",
    "    #print('TensorList_star[1] = ', TensorList_star[1])\n",
    "    #print('TensorList_star[2] = ', TensorList_star[2])\n",
    "    TensorList_temp = TensorList_star[:]    #everything is behaving as expected\n",
    "    #print('TensorList_temp[0] After = ', TensorList_temp[0])\n",
    "    #print('TensorList_temp[1] After = ', TensorList_temp[1])\n",
    "    #print('TensorList_temp[2] After = ', TensorList_temp[2])\n",
    "    #print('indxList_star[2] before = ', indxList_star[2])\n",
    "    indxList = indxList_star[:]     # don't really need to update this cause these don't really change\n",
    "    #print('indxList[2] after = ', indxList[2])\n",
    "    #print('TensorList_star[0] =',  TensorList_star[0])\n",
    "    TensorList  = TensorList_star[:]  #everything is behaving as expected\n",
    "    #print('TensorList[0] =',  TensorList[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(LostList)\n",
    "print('loss function approaches =', LostList[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
