{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/__init__.py:144: UserWarning: Numpy 1.13.3 or above is required for this version of scipy (detected version 1.13.1)\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "# for Compute RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_repeated_Indices(list_of_indices):\n",
    "    #input: string of indices for the tensors. \n",
    "    #output: string of repeated indices. code takes in indices and output only the repeated indices\n",
    "    #Ex: Suppose tensor A has index ijkp, and tensor B has index klpm.\n",
    "    #then get_repeated_Indices('ijkp', 'klpm') will return the following string: 'kp'\n",
    "    myList = list_of_indices\n",
    "    #convert List to string\n",
    "    myString =''.join(myList)\n",
    "    #break the string into indivual list of characters ex.  'abc' ->['a','b', 'c']\n",
    "    myList = list(myString)\n",
    "    #get the repeated frequencies of each indices\n",
    "    my_dict = {i:myList.count(i) for i in myList}\n",
    "    \n",
    "    repeatedList = []\n",
    "    for item in my_dict:\n",
    "        if my_dict[item] > 1:\n",
    "            repeatedList.append(item)\n",
    "    return repeatedList\n",
    "\n",
    "def  remove_Repeated_indices(List_of_indices):\n",
    "    #inputs: tensor indices in the form of string\n",
    "    #output: string of non repeated indicies\n",
    "    #Ex: remove_Repeated_indices('abc', 'cde')\n",
    "    #output of the example would be: 'abde'\n",
    "    \n",
    "    myList = List_of_indices \n",
    "    #turn myList into String: Ex: ['abc','cde'] -> 'abccde'\n",
    "    myString = ''.join(myList)\n",
    "    #turn back into lists again: Exp: from 'abccde' -> ['a','b','c','c','d','e']\n",
    "    myList = list(myString)\n",
    "    repeated_indices = get_repeated_Indices(List_of_indices)\n",
    "    #print('the repeated list of indices are:', repeated_indices)\n",
    "    unique_indices = []\n",
    "    #now we remove repeated indices from myList\n",
    "    for item in myList:\n",
    "        if item not in repeated_indices:\n",
    "            unique_indices.append(item)\n",
    "    uniqueString = ''.join(unique_indices)   \n",
    "    return uniqueString\n",
    "\n",
    "def einSum_Contraction(tensorList, indxList):  #<----should rename this to einSum_Contraction to replace old code\n",
    "    #Purpose: this function takes a list of tensors, and list of indices, and indix to contract and uses einstien summation to perform contraction\n",
    "    #ex: tensorList = [tensor1, tensor2, tensor3]\n",
    "    #indxList   = [indx1, indx2, indx3]\n",
    "    myList = []\n",
    "    uniqueIndices = remove_Repeated_indices(indxList)\n",
    "    inputIndices = [indxList]\n",
    "    N = len(indxList)\n",
    "    #myList = [indx1, ',',indx2,',',indx3,'->', uniqueIndices] \n",
    "    for i in range(N - 1):\n",
    "        myList.append(indxList[i])\n",
    "        myList.append(',') \n",
    "    myList.append(indxList[N-1])\n",
    "    myList.append('->')\n",
    "    myList.append(uniqueIndices)\n",
    "    #convert myList to a string: i.e.  [indx1, ',',indx2,',',indx3,'->', uniqueIndices]  - >'ijk,klm,mjp->ilp'\n",
    "    myString = ''.join(myList)\n",
    "    #print('myString = ', myString)\n",
    "    C = torch.einsum(myString, tensorList)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padTensor(tensor, pad_axis):\n",
    "    #this is for the discrete optimization\n",
    "    #this function takes a tensor and append an extra dimension of ~ zeros along the specified axis (we call the pad axis)\n",
    "    if pad_axis == -1:\n",
    "        return tensor #don't pad anything\n",
    "    tensorShape = list(tensor.shape)\n",
    "    tensorShape[pad_axis] = 1  #increase the dimension up by 1\n",
    "    zerosPad = torch.rand(tensorShape) *1e-6  #pad with values approx. equal to zero\n",
    "    padded_tensor = torch.cat([tensor, zerosPad], pad_axis)\n",
    "    #print('padded_tensor.shape = ', padded_tensor.shape)\n",
    "    #print('padded_tensor function output = ', padded_tensor)\n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def increaseRank(Tensor1, Tensor2, indx1, indx2):\n",
    "    # The indx 1 and index2 represents the indices for tensor 1 and 2 respectively. \n",
    "    #There is only one repeated index in the list (indx1, indx2). The repeated index represents the shared edge between\n",
    "    #the two tensors. For ex: ijkl, lmno\n",
    "    alpha = get_repeated_Indices([indx1, indx2])\n",
    "    if len(alpha) != 0 :\n",
    "        #convert alpha to string\n",
    "        alpha = ''.join(alpha)\n",
    "        # find the position of the repeated index alpha in indx1 and indx2\n",
    "        padAxes1 = indx1.index(alpha)\n",
    "        padAxes2 = indx2.index(alpha)  \n",
    "        Tensor1 = padTensor(Tensor1, padAxes1)\n",
    "        Tensor2 = padTensor(Tensor2, padAxes2)\n",
    "    return  Tensor1, Tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Tensor_Generator(TensorDimension):\n",
    "#input: desired target tensor dimension in the form of a list. Ex: input d1xd2xd3 as [d1, d2, d3]\n",
    "#output: target tensor with random entries drawn from a normal distribution of mean=0 and variance=1\n",
    "    Tensor = torch.randn(TensorDimension)\n",
    "    return Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOneData_point(W):\n",
    "# W is input tensor\n",
    "#X are drawn from a normal distribution of mean=0 and variance=1 \n",
    "#output: Xi, yi  = targetTensor * X\n",
    "    indxList = []\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    Xi = Tensor_Generator(W.shape) #generate Tensor Xi with same shape as input tensor W\n",
    "    for j in range(len(Xi.shape)):\n",
    "        indxList.append(alphabet[j])\n",
    "        indx = ''.join(indxList)\n",
    "    tensorList = [W, Xi]\n",
    "    #W and X have same index so that yi is a scaler\n",
    "    yi = einSum_Contraction([W,Xi], [indx, indx])\n",
    "    return Xi, yi, indx  #W and Xi shares the same indx\n",
    "\n",
    "def data_Set_Generator(tensor, N):\n",
    "    #N = number of training data you want\n",
    "    #tensor is usually the target tensor \n",
    "    Xi_set = []\n",
    "    yi_set = []\n",
    "    for i in range(N):\n",
    "        Xi, yi, indx = getOneData_point(tensor)\n",
    "        Xi_set.append(Xi)\n",
    "        yi_set.append(yi)\n",
    "    return Xi_set, yi_set,indx  #tensor and Xi shares the same indx\n",
    "\n",
    "def getYi_set(Xi_set, tensor, indxList):\n",
    "    #this function generates a N number of yi's using yi = tensor*Xi_set[i]. \n",
    "    #The input tensor is usually either the approx. tensor or the target tensor.\n",
    "    #indxList = [indx_Xi, indx_tensor]\n",
    "    yi_set = []\n",
    "    N = len(Xi_set)      #is there are N elements of Xi in Xi_set, there will be N elements of yi in yi_set\n",
    "    for i in range(N):\n",
    "        yi = einSum_Contraction([tensor,Xi_set[i]], indxList)\n",
    "        yi_set.append(yi)\n",
    "    return yi_set\n",
    "\n",
    "def innerProduct_Tensor(T,A):\n",
    "    #input: inner product of two tensors T and A of same dimension equals the sum of the product of their entries \n",
    "    #covert T, and A tensors in to 1 D tensors\n",
    "    T = T.view(1,-1)   #convert tensor  to 1D\n",
    "    T = T.squeeze()    #squeeze out any extra dimension\n",
    "    A = A.view(1,-1)\n",
    "    A = A.squeeze()\n",
    "    #perform inner product of two 1D tensors\n",
    "    yi = sum(torch.mul(T,A))\n",
    "    return yi\n",
    "\n",
    "def printRank(TensorList):\n",
    "    [r5,r6,r7,r8] = (TensorList[4].shape) #tensor G dimension\n",
    "    [r4,d4,r3,r5] = (TensorList[3].shape) #tensor D dimension\n",
    "    [r2,d1,r1,r7] = (TensorList[0].shape) #tensor A dimension\n",
    "    r = [r1,r2,r3,r4,r5,r6,r7,r8]\n",
    "    return r\n",
    "\n",
    "def getNumParams(r):\n",
    "    #r = list of ranks of a tensor\n",
    "    numParam = d1*r[0]*r[6]*r[1] + d2*r[0]*r[7]*r[3]+ d3*r[1]*r[5]*r[2] + d4*r[3]*r[4]*r[2] + r[4]*r[5]*r[6]*r[7]\n",
    "    return numParam\n",
    "\n",
    "def getNumParams_stoch(r):\n",
    "    #r = [r0,r1,r2,r3,...,r7] \n",
    "    #we want to compuate the dimension of the block we start with. For exmape\n",
    "    #we started with 4 order tensor, which can be approximated by 5 tensors\n",
    "    #below computes the number of params for each of the tensor\n",
    "    numParam1 = d1*r[0]*r[6]*r[1]\n",
    "    numParam2 = d2*r[0]*r[7]*r[3]\n",
    "    numParam3 = d3*r[1]*r[5]*r[2]\n",
    "    numParam4 = d4*r[3]*r[4]*r[2]\n",
    "    numParamCore = r[4]*r[5]*r[6]*r[7] \n",
    "    numParamList = [numParam1, numParam2, numParam3, numParam4, numParamCore]\n",
    "    return numParamList\n",
    "\n",
    "def computeLoss_Regression(yi_set, Xi_set, approxTensor):\n",
    "    #N is total number of training/test data\n",
    "    sum = 0\n",
    "    N = len(yi_set)\n",
    "    for i in range(N):\n",
    "        # y_approx = innerProduct(ApproxTensor, X_i)\n",
    "        y_approx = innerProduct_Tensor(approxTensor, Xi_set[i])\n",
    "        loss = (yi_set[i] - y_approx)**2\n",
    "        sum = sum + loss\n",
    "    #divide by N to average the squared error of the cost function  so that the cost function doesn't depend on the number \n",
    "    #of elements in the training set.\n",
    "    total_loss = 1/(2*N)*sum \n",
    "    return(total_loss)\n",
    "\n",
    "def get_RandomSeqence(seqLength,d):\n",
    "    #input: seqLength = len(r)  where r = [r0()),...r(n)]\n",
    "    #input d: maxvalue a rank can take be set to i.e 1=<r<=d\n",
    "    #return: a list of random ranks with each element ranging beween 1=<r<=d\n",
    "    r = []\n",
    "    for i in range(seqLength):\n",
    "        r.append(random.randint(1,d))\n",
    "    return \n",
    "\n",
    "def increaseRank(Tensor1, Tensor2, indx1, indx2):\n",
    "    # The indx 1 and index2 represents the indices for tensor 1 and 2 respectively. \n",
    "    #There is only one repeated index in the list (indx1, indx2). The repeated index represents the shared edge between\n",
    "    #the two tensors. For ex: ijkl, lmno\n",
    "    alpha = get_repeated_Indices([indx1, indx2])\n",
    "    if len(alpha) != 0 :\n",
    "        #convert alpha to string\n",
    "        alpha = ''.join(alpha)\n",
    "        # find the position of the repeated index alpha in indx1 and indx2\n",
    "        padAxes1 = indx1.index(alpha)\n",
    "        padAxes2 = indx2.index(alpha)  \n",
    "        Tensor1 = padTensor(Tensor1, padAxes1)\n",
    "        Tensor2 = padTensor(Tensor2, padAxes2)\n",
    "    return  Tensor1, Tensor2\n",
    "\n",
    "def getNextDirection(r_list):\n",
    "    #this function is for random walk\n",
    "    #input: r_list = [r0,r1,...r7] \n",
    "    #output: nextDirection is a scaler that index the position of rank chosen\n",
    "    nextDirection = random.randint(0, len(r_list)-1)\n",
    "    print('nextDirection = ', nextDirection)\n",
    "    return nextDirection\n",
    "\n",
    "def get_Next_randomEdge(nextDirection1, r_list):   \n",
    "    #this function is for random walk\n",
    "    #input: r_list = [r0,r1,...r7] \n",
    "    #       nextDirection = scaler. \n",
    "    #output: chosen random edge\n",
    "    nextDirection1 = random.randint(0, len(r_list)-1)\n",
    "    #print('nextDirection = ', nextDirection)\n",
    "    r_list[nextDirection1] = 1 + r_list[nextDirection1]\n",
    "    return r_list\n",
    "\n",
    "\n",
    "def get_indexString(chosenEdge, indxList):\n",
    "     #this function is for random walk\n",
    "    #goal: returns all the index strings that contains the input letter\n",
    "    #input: chosenEdge = an alphebtical letter. Ex: l\n",
    "    #       indexList1: list of strings of indices. Ex:indxList1 = [kilc', 'ljed', 'eabc']\n",
    "    #output: indexStringList: elements in list containing chosenEdge. Ex: if choseEdge = 1, then code will return IndexStringList = [kilc', 'ljed'] \n",
    "           # indx: positon in the list containing the chosenEdge.\n",
    "    indexStringList = []\n",
    "    indx = []\n",
    "    position = 0\n",
    "    for indexString in indxList:\n",
    "        if chosenEdge in indexString:\n",
    "            indexStringList.append(indexString)\n",
    "            indx.append(position)  \n",
    "           # print('position = ', position, 'indexString = ', indexString)\n",
    "        position = position + 1\n",
    "    return indexStringList, indx\n",
    "\n",
    "def solve_Continuous(target_Tensor, tensorList, indxList, iterNum):\n",
    "#input: list of tensors and their corresponding indices\n",
    "#Goal: The purpose of this function is to solve the innerloop of the optimization for the problem\n",
    "    len_Tensor = len(tensorList)\n",
    "    len_Indx   = len(indxList)\n",
    "    for i in range(len_Tensor):\n",
    "        tensorList[i] = tensorList[i].detach()\n",
    "        tensorList[i].requires_grad = True\n",
    "    #defines a SGD optimizer to update the parameters\n",
    "    #optimizer = optim.SGD(tensorList lr = 0.001, momentum=0.2)\n",
    "    optimizer = optim.Adam(tensorList, lr=0.009)\n",
    "    #initialize parameters      \n",
    "    LostList = []              #use this to plot the lost function\n",
    "    for i in range(iterNum):\n",
    "        optimizer.zero_grad()\n",
    "        tensor_approx = einSum_Contraction(tensorList, indxList)\n",
    "        #loss_fn = computeLoss(tensor_approx, target_Tensor)   # this is for tensor decomp: ||W_target - W_approx||_FË†2\n",
    "        loss_fn =computeLoss_Regression(yi_train, Xi_train, tensor_approx)\n",
    "        loss_fn.backward()\n",
    "        optimizer.step()                # the new A,B,C will be A_k+1,B_k+1, C_k+1 after optimizer.step \n",
    "        LostList.append(float(loss_fn))\n",
    "    return tensorList, indxList, LostList\n",
    "\n",
    "def greedyMethod(indxList, maxParam, numOuter_iterations, TensorList, TensorList_temp):\n",
    "    #maxParam = number of parameters in target tensor\n",
    "    #list of indices for the initial block tensors\n",
    "    \n",
    "    #Initialize data\n",
    "    iterNum=20   #500\n",
    "    Lost_star = 1e12  #set it to be any large number\n",
    "    check = 1\n",
    "    numParam = -1\n",
    "    paramKey = -1\n",
    "    greedy_loss_List = []  # list of Lostlist[-1]\n",
    "    RMSE_greedy_list = []\n",
    "    \n",
    "    for k in range(numOuter_iterations):   #discrete optimizaton loop\n",
    "        if paramKey == 1:\n",
    "            break\n",
    "        for i in range(len(TensorList_temp)):\n",
    "            if paramKey == 1:\n",
    "                break\n",
    "            for j in range(i,len(TensorList_temp)):\n",
    "                if paramKey == 1:\n",
    "                    break\n",
    "                if i==j:\n",
    "                    continue\n",
    "            #print(i,j)\n",
    "            #check num of paramters for the newly updated ranks\n",
    "           # rt = list of ranks: [r1_t,r2_t,r3_t,r4_t,r5_t,r6_t,r7_t,r8_t]\n",
    "                rt = printRank(TensorList_temp)\n",
    "                numParam_temp = getNumParams(rt)\n",
    "                print('numParam_greedy=', numParam_temp)\n",
    "                if numParam_temp > maxParam:\n",
    "                    paramKey = 1\n",
    "                    print('Max number of parameters exceeded. Current Param = ', numParam_temp, 'and max Param allowed = ', maxParam)\n",
    "                    print('program finish ')\n",
    "                    break\n",
    "                #solve continuous part\n",
    "                [TensorList_temp, indxList, LostList] = solve_Continuous(target_Tensor, TensorList_temp, indxList, iterNum)\n",
    "                printRank(TensorList_temp)\n",
    "                #store the optimal value for a given point around its neighbour\n",
    "                if Lost_star > LostList[-1]: \n",
    "                        indx_star = [i,j]\n",
    "                        TensorList_star = TensorList_temp[:]\n",
    "                        indxList_star = indxList[:]  \n",
    "                        Lost_star = LostList[-1]  \n",
    "                        r_greedy = printRank(TensorList_star)\n",
    "                        print('r_greedy = ', r_greedy)\n",
    "                        numParam = getNumParams(r_greedy )\n",
    "                        check = -1\n",
    "                elif Lost_star <= LostList[-1]:\n",
    "                    print('k = ', k, 'Lowest Loss found so far = ', Lost_star, 'Current Loss = ', LostList[-1])\n",
    "                    print('Loss previous is less than current, so no rank update is made at this iteration')\n",
    "                    print('total number of parameters for best chosen rank = ', numParam)\n",
    "         \n",
    "                #Reset TensorList_temp to continue with greedy at another point\n",
    "                TensorList_temp = TensorList[:] #set back to previous position to continue with greedy search arounnd the point       \n",
    "                #increase the ranks of the tensors\n",
    "                [TensorList_temp[i],TensorList_temp[j]] = increaseRank(TensorList_temp[i], TensorList_temp[j],  indxList[i], indxList[j])            \n",
    "        #update parameters   \n",
    "        TensorList_temp = TensorList_star[:]    #everything is behaving as expected\n",
    "        indxList = indxList_star[:]     # don't really need to update this cause these don't really change\n",
    "        TensorList_greedy   = TensorList_star[:]  #everything is behaving as expected\n",
    "        greedy_loss_List.append(Lost_star)\n",
    "    #TensorList contains decomposed block of tensors. We use einsum to combine them into one \n",
    "    #big tensor Tapprox_greedy\n",
    "    Tapprox_greedy = einSum_Contraction(TensorList_greedy, indxList)  #TensorList_Greedy = TensorList\n",
    "    print('Tapprox_greedy.shape = ', Tapprox_greedy.shape)\n",
    "\n",
    "    #generate yi_approx = tensorApprox_star * X_i. Plot this set of yi_approx, with yi\n",
    "    indxlist_greedy = ['abcd', 'abcd']   # abcd =  = d1*d2*d3*d4 i.e. each alphabet represents each dimension ot target tensor\n",
    "    yi_approxSet_greedy = getYi_set(Xi_test, Tapprox_greedy, indxlist_greedy)\n",
    "    print('len(yi_approxSet_greedy) = ', len(yi_approxSet_greedy))\n",
    "    return yi_approxSet_greedy, greedy_loss_List\n",
    "\n",
    "#***********************RANDOM WALK*****************************************\n",
    "def randomWalk(TensorList_RW, maxParam, Xi_set):\n",
    "#input: maxParam = number of parameters in target tensor\n",
    "# Xi_set: could be the traing set or test set \n",
    "    #initialize the edges to 1\n",
    "    r_RW = [1,1,1,1,1,1,1,1]   #rank list for random walk\n",
    "    rankList_indx = ['l', 'k', 'g', 'e', 'a', 'b', 'c', 'd']\n",
    "    iterNum = 20 #100          #number of iterations for continuous optimization\n",
    "    numParam_RW = getNumParams(r_RW)\n",
    "    indxListRW = indxList1     #indxList1 is a global variable\n",
    "    RW_lost_list = []\n",
    "    TensorList_RW = TensorList1[:] # TensorList1  = [A_0,B_0,C_0,D_0,G_0] \n",
    "    RMSE_RW = []\n",
    "    while maxParam > numParam_RW:\n",
    "        numParam_RW = getNumParams(r_RW)\n",
    "        #initialize tensor \n",
    "        if maxParam > numParam_RW:\n",
    "            #recall target_tensor and is a global variable\n",
    "            [TensorList_RW, indxListRW, LostList_RW] = solve_Continuous(target_Tensor, TensorList_RW, indxListRW, iterNum)\n",
    "            RW_lost_list.append(LostList_RW[-1])  \n",
    "            nextDirection = getNextDirection(r_RW) \n",
    "            chosenEdge = rankList_indx[nextDirection]\n",
    "            r_RW = get_Next_randomEdge(nextDirection, r_RW)\n",
    "            print('next direction =', nextDirection,'r_RW = ', r_RW)\n",
    "            rankString, Tensor_indexRW = get_indexString(chosenEdge, indxList1)  #rankString is a list. Ex. ['abc','kbg']\n",
    "            #increaseRank and padded new dimensions with approx. 0\n",
    "            [TensorList_RW[Tensor_indexRW[0]], TensorList_RW[Tensor_indexRW[1]]] = increaseRank(TensorList_RW[Tensor_indexRW[0]], TensorList_RW[Tensor_indexRW[1]], rankString[0], rankString[1])      \n",
    "            print('Random Walk: numParam = ', numParam_RW, 'maxNumParam of target tensor = ', maxParam)\n",
    "        else:\n",
    "            print('')\n",
    "            print('program finished! cant perform another loop else will get numParameters > maxParam')\n",
    "\n",
    "    #take the block tensors and combine them to form 1 big tensor: TensorApprox_RW \n",
    "    # indxList1 = [indxA, indxB, indxC, indxD, indxG]. We use the exact same indxList as the ones above\n",
    "    TensorApprox_RW = einSum_Contraction([TensorList_RW[0], TensorList_RW[1], TensorList_RW[2], TensorList_RW[3], TensorList_RW[4]], indxList1)\n",
    "    indxlist_RW = ['abcd', 'abcd']   # abcd =  = d1*d2*d3*d4 i.e. each alphabet represents each dimension ot target tensor\n",
    "    yi_approxSet_RW = getYi_set(Xi_set, TensorApprox_RW, indxlist_RW)\n",
    "    \n",
    "    return yi_approxSet_RW \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                         ######***Eperiment****** ######\n",
    "#generate 4-order target tensor\n",
    "#see ipad for supplementary notes on this tensor and its diagram\n",
    "\n",
    "#Start with 5 nodes (not 4 cause we are including a core node)\n",
    "d1 = 3\n",
    "d2 = 3\n",
    "d3 = 3\n",
    "d4 = 3\n",
    "d5 = 3\n",
    "r0 = 2\n",
    "r1 = 3\n",
    "r2 = 4\n",
    "r3 = 3\n",
    "r4 = 2\n",
    "r5 = 3\n",
    "r6 = 2\n",
    "r7 = 2\n",
    "\n",
    "noise = 1e-6\n",
    "#generate at random target tensor\n",
    "\n",
    "A = torch.rand(r1,d1,r0,r6) # + torch.rand(r1,d1,r0,r6)*noise\n",
    "B = torch.rand(r0,d2,r3,r7) # + torch.rand(r0,d2,r3,r7)*noise\n",
    "C = torch.rand(r1,d3,r2,r5) # + torch.rand(r1,d3,r2,r5)*noise\n",
    "D = torch.rand(r3,d4,r2,r4) # + torch.rand(r3,d4,r2,r4)*noise \n",
    "G = torch.rand(r4,r5,r6,r7) # + torch.rand(r4,r5,r6,r7)*noise   #core node\n",
    "\n",
    "indxA = 'kilc'\n",
    "indxB = 'ljed'\n",
    "indxC = 'khgb'\n",
    "indxD = 'efga'\n",
    "indxG = 'abcd'   #core tensor\n",
    "\n",
    "indxList1 = [indxA, indxB, indxC, indxD, indxG]\n",
    "target_Tensor = einSum_Contraction([A,B,C,D,G], [indxA, indxB, indxC, indxD, indxG])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate training and test sets\n",
    "N=20\n",
    "#p is the percentage of the total number of data N\n",
    "p = int(np.floor(0.65*20))  #so is is 65% of the original data\n",
    "[Xi_data, yi_data, indx] = data_Set_Generator(target_Tensor, N) \n",
    "Xi_train = Xi_data[0:p]\n",
    "yi_train  = yi_data[0:p]\n",
    "Xi_test = Xi_data[p:N+1]\n",
    "yi_test = yi_data[p:N+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxParam allowed =  81\n",
      "nextDirection =  2\n",
      "next direction = 2 r_RW =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "Random Walk: numParam =  13 maxNumParam of target tensor =  81\n",
      "nextDirection =  6\n",
      "next direction = 6 r_RW =  [1, 1, 2, 1, 2, 1, 1, 1]\n",
      "Random Walk: numParam =  19 maxNumParam of target tensor =  81\n",
      "nextDirection =  1\n",
      "next direction = 1 r_RW =  [1, 1, 2, 1, 2, 2, 1, 1]\n",
      "Random Walk: numParam =  26 maxNumParam of target tensor =  81\n",
      "nextDirection =  6\n",
      "next direction = 6 r_RW =  [1, 1, 3, 1, 2, 2, 1, 1]\n",
      "Random Walk: numParam =  34 maxNumParam of target tensor =  81\n",
      "nextDirection =  6\n",
      "next direction = 6 r_RW =  [2, 1, 3, 1, 2, 2, 1, 1]\n",
      "Random Walk: numParam =  46 maxNumParam of target tensor =  81\n",
      "nextDirection =  4\n",
      "next direction = 4 r_RW =  [3, 1, 3, 1, 2, 2, 1, 1]\n",
      "Random Walk: numParam =  52 maxNumParam of target tensor =  81\n",
      "nextDirection =  4\n",
      "next direction = 4 r_RW =  [3, 1, 3, 1, 2, 2, 2, 1]\n",
      "Random Walk: numParam =  58 maxNumParam of target tensor =  81\n",
      "nextDirection =  7\n",
      "next direction = 7 r_RW =  [3, 1, 3, 2, 2, 2, 2, 1]\n",
      "Random Walk: numParam =  71 maxNumParam of target tensor =  81\n",
      "\n",
      "program finished! cant perform another loop else will get numParameters > maxParam\n",
      "nextDirection =  4\n",
      "next direction = 4 r_RW =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "Random Walk: numParam =  13 maxNumParam of target tensor =  81\n",
      "nextDirection =  5\n",
      "next direction = 5 r_RW =  [1, 1, 2, 1, 1, 1, 1, 2]\n",
      "Random Walk: numParam =  19 maxNumParam of target tensor =  81\n",
      "nextDirection =  3\n",
      "next direction = 3 r_RW =  [1, 1, 2, 1, 2, 1, 1, 2]\n",
      "Random Walk: numParam =  23 maxNumParam of target tensor =  81\n",
      "nextDirection =  0\n",
      "next direction = 0 r_RW =  [1, 1, 2, 1, 2, 1, 1, 3]\n",
      "Random Walk: numParam =  31 maxNumParam of target tensor =  81\n",
      "nextDirection =  1\n",
      "next direction = 1 r_RW =  [1, 1, 2, 1, 2, 1, 2, 3]\n",
      "Random Walk: numParam =  36 maxNumParam of target tensor =  81\n",
      "nextDirection =  2\n",
      "next direction = 2 r_RW =  [2, 1, 2, 1, 2, 1, 2, 3]\n",
      "Random Walk: numParam =  45 maxNumParam of target tensor =  81\n",
      "nextDirection =  2\n",
      "next direction = 2 r_RW =  [2, 1, 2, 1, 2, 1, 3, 3]\n",
      "Random Walk: numParam =  60 maxNumParam of target tensor =  81\n",
      "nextDirection =  6\n",
      "next direction = 6 r_RW =  [2, 1, 2, 1, 2, 1, 3, 4]\n",
      "Random Walk: numParam =  72 maxNumParam of target tensor =  81\n",
      "\n",
      "program finished! cant perform another loop else will get numParameters > maxParam\n",
      "t =  1 RMSE_RW =  0\n",
      "numParam_greedy= 13\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [2, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 13\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 2, 1]\n",
      "numParam_greedy= 13\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 1, 2, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 2]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "r_greedy =  [1, 1, 1, 1, 1, 2, 1, 1]\n",
      "Tapprox_greedy.shape =  torch.Size([3, 3, 3, 3])\n",
      "len(yi_approxSet_greedy) =  7\n",
      "t =  2 RMSE_RW =  0\n",
      "numParam_greedy= 13\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [2, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  0 Lowest Loss found so far =  116.80997467041016 Current Loss =  142.5843505859375\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  0 Lowest Loss found so far =  116.80997467041016 Current Loss =  120.74215698242188\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 2, 1]\n",
      "numParam_greedy= 13\n",
      "k =  0 Lowest Loss found so far =  78.1336898803711 Current Loss =  80.34060668945312\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  17\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 1, 2, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  73.02108764648438 Current Loss =  79.53172302246094\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  58.74645233154297 Current Loss =  83.25994873046875\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  23.803483963012695 Current Loss =  75.79793548583984\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  23.803483963012695 Current Loss =  67.01609802246094\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  23.803483963012695 Current Loss =  78.5927734375\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  23.803483963012695 Current Loss =  79.09955596923828\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  23.803483963012695 Current Loss =  81.90969848632812\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  23.803483963012695 Current Loss =  75.81321716308594\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  23.803483963012695 Current Loss =  81.05797576904297\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  23.803483963012695 Current Loss =  78.25067138671875\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  23.803483963012695 Current Loss =  80.23817443847656\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "Tapprox_greedy.shape =  torch.Size([3, 3, 3, 3])\n",
      "len(yi_approxSet_greedy) =  7\n",
      "t =  3 RMSE_RW =  0\n",
      "numParam_greedy= 13\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [2, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 13\n",
      "k =  0 Lowest Loss found so far =  71.29541015625 Current Loss =  82.69620513916016\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  71.29541015625 Current Loss =  81.44783020019531\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  0 Lowest Loss found so far =  71.29541015625 Current Loss =  79.6703109741211\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  0 Lowest Loss found so far =  71.29541015625 Current Loss =  79.07738494873047\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  71.29541015625 Current Loss =  83.3727798461914\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  64.3000717163086 Current Loss =  82.16265869140625\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  32.73167037963867 Current Loss =  77.39057159423828\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  32.73167037963867 Current Loss =  66.28870391845703\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  32.73167037963867 Current Loss =  79.47013092041016\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  32.73167037963867 Current Loss =  83.71894073486328\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  32.73167037963867 Current Loss =  80.06739807128906\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  32.73167037963867 Current Loss =  73.62389373779297\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  32.73167037963867 Current Loss =  82.96825408935547\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  32.73167037963867 Current Loss =  80.68833923339844\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  32.73167037963867 Current Loss =  81.57428741455078\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  14.874593734741211 Current Loss =  74.16075134277344\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  14.874593734741211 Current Loss =  70.08782958984375\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  2 Lowest Loss found so far =  14.874593734741211 Current Loss =  79.7125244140625\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  14.874593734741211 Current Loss =  79.10887908935547\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  2 Lowest Loss found so far =  14.874593734741211 Current Loss =  81.78176879882812\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  14.874593734741211 Current Loss =  76.75862121582031\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  14.874593734741211 Current Loss =  79.91148376464844\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  14.874593734741211 Current Loss =  81.04856872558594\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  14.874593734741211 Current Loss =  81.02587890625\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "Tapprox_greedy.shape =  torch.Size([3, 3, 3, 3])\n",
      "len(yi_approxSet_greedy) =  7\n",
      "t =  4 RMSE_RW =  0\n",
      "numParam_greedy= 13\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [2, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 13\n",
      "k =  0 Lowest Loss found so far =  76.87520599365234 Current Loss =  82.5408706665039\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  76.87520599365234 Current Loss =  81.32291412353516\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  0 Lowest Loss found so far =  76.87520599365234 Current Loss =  79.87471771240234\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 1, 2, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  72.02244567871094 Current Loss =  83.6313705444336\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  62.4664421081543 Current Loss =  82.74529266357422\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  24.77899169921875 Current Loss =  77.84940338134766\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  24.77899169921875 Current Loss =  71.38065338134766\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  24.77899169921875 Current Loss =  79.89308166503906\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  24.77899169921875 Current Loss =  80.8628921508789\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  24.77899169921875 Current Loss =  78.40345764160156\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  24.77899169921875 Current Loss =  78.4458999633789\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  24.77899169921875 Current Loss =  79.85821533203125\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  24.77899169921875 Current Loss =  81.8121566772461\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1 Lowest Loss found so far =  24.77899169921875 Current Loss =  79.97479248046875\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  5.7055840492248535 Current Loss =  73.66370391845703\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  5.7055840492248535 Current Loss =  72.2882308959961\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  2 Lowest Loss found so far =  5.7055840492248535 Current Loss =  80.15557098388672\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  5.7055840492248535 Current Loss =  78.16055297851562\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  2 Lowest Loss found so far =  5.7055840492248535 Current Loss =  77.91889953613281\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  5.7055840492248535 Current Loss =  71.76056671142578\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  5.7055840492248535 Current Loss =  82.18346405029297\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  5.7055840492248535 Current Loss =  69.52149963378906\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  5.7055840492248535 Current Loss =  80.69255828857422\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  5.7055840492248535 Current Loss =  14.020310401916504\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  5.7055840492248535 Current Loss =  73.8672866821289\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  5.7055840492248535 Current Loss =  64.58830261230469\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  3 Lowest Loss found so far =  5.7055840492248535 Current Loss =  80.00267791748047\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  5.7055840492248535 Current Loss =  77.81867980957031\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  3 Lowest Loss found so far =  5.7055840492248535 Current Loss =  79.41749572753906\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  5.7055840492248535 Current Loss =  77.85567474365234\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  5.7055840492248535 Current Loss =  79.37535858154297\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  5.7055840492248535 Current Loss =  64.91585540771484\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  5.7055840492248535 Current Loss =  82.06089782714844\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "Tapprox_greedy.shape =  torch.Size([3, 3, 3, 3])\n",
      "len(yi_approxSet_greedy) =  7\n",
      "t =  5 RMSE_RW =  0\n",
      "numParam_greedy= 13\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [2, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 13\n",
      "k =  0 Lowest Loss found so far =  70.8698501586914 Current Loss =  82.5323486328125\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  70.8698501586914 Current Loss =  81.31370544433594\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  0 Lowest Loss found so far =  70.8698501586914 Current Loss =  79.8895034790039\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  0 Lowest Loss found so far =  70.8698501586914 Current Loss =  78.98834991455078\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  70.8698501586914 Current Loss =  77.96446990966797\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  68.21044158935547 Current Loss =  79.79415130615234\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  34.991119384765625 Current Loss =  77.1744155883789\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  34.991119384765625 Current Loss =  71.18529510498047\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  34.991119384765625 Current Loss =  78.77643585205078\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  34.991119384765625 Current Loss =  79.18260955810547\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  34.991119384765625 Current Loss =  83.03585052490234\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  34.991119384765625 Current Loss =  80.39688110351562\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  34.991119384765625 Current Loss =  80.06743621826172\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1 Lowest Loss found so far =  34.991119384765625 Current Loss =  81.04820251464844\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  34.991119384765625 Current Loss =  80.99176025390625\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  14.931836128234863 Current Loss =  73.15251922607422\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  14.931836128234863 Current Loss =  74.74822998046875\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  2 Lowest Loss found so far =  14.931836128234863 Current Loss =  79.58921813964844\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  14.931836128234863 Current Loss =  78.84381103515625\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  2 Lowest Loss found so far =  14.931836128234863 Current Loss =  81.36251068115234\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  14.931836128234863 Current Loss =  71.8287124633789\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  14.931836128234863 Current Loss =  79.58912658691406\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  14.931836128234863 Current Loss =  64.1306381225586\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  14.931836128234863 Current Loss =  83.16151428222656\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  14.931836128234863 Current Loss =  15.28573989868164\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  14.931836128234863 Current Loss =  72.20124816894531\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  14.931836128234863 Current Loss =  72.0922622680664\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  3 Lowest Loss found so far =  14.931836128234863 Current Loss =  79.93968200683594\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  14.931836128234863 Current Loss =  78.10900115966797\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  3 Lowest Loss found so far =  14.931836128234863 Current Loss =  78.46068572998047\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  14.931836128234863 Current Loss =  72.12300109863281\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  14.931836128234863 Current Loss =  80.21833801269531\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  14.931836128234863 Current Loss =  62.47510528564453\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  14.931836128234863 Current Loss =  78.22896575927734\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  14.931836128234863 Current Loss =  18.99378204345703\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  14.931836128234863 Current Loss =  78.74647521972656\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  14.931836128234863 Current Loss =  71.56743621826172\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  4 Lowest Loss found so far =  14.931836128234863 Current Loss =  79.31866455078125\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  4 Lowest Loss found so far =  14.931836128234863 Current Loss =  81.57649993896484\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  4 Lowest Loss found so far =  14.931836128234863 Current Loss =  83.56844329833984\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  14.931836128234863 Current Loss =  79.14391326904297\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  4 Lowest Loss found so far =  14.931836128234863 Current Loss =  78.84036254882812\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  14.931836128234863 Current Loss =  71.0602035522461\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  4 Lowest Loss found so far =  14.931836128234863 Current Loss =  80.84382629394531\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "Tapprox_greedy.shape =  torch.Size([3, 3, 3, 3])\n",
      "len(yi_approxSet_greedy) =  7\n",
      "t =  6 RMSE_RW =  0\n",
      "numParam_greedy= 13\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [2, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 13\n",
      "k =  0 Lowest Loss found so far =  67.28438568115234 Current Loss =  82.71508026123047\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  67.28438568115234 Current Loss =  81.60282135009766\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  0 Lowest Loss found so far =  67.28438568115234 Current Loss =  78.65245819091797\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  0 Lowest Loss found so far =  67.28438568115234 Current Loss =  77.78730773925781\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  67.28438568115234 Current Loss =  83.62897491455078\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  0 Lowest Loss found so far =  67.28438568115234 Current Loss =  75.76081848144531\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  67.28438568115234 Current Loss =  82.18215942382812\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  40.93523406982422 Current Loss =  79.34508514404297\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  40.93523406982422 Current Loss =  75.2198257446289\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  40.93523406982422 Current Loss =  82.48734283447266\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  40.93523406982422 Current Loss =  81.47786712646484\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  40.93523406982422 Current Loss =  78.83021545410156\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  40.93523406982422 Current Loss =  79.49014282226562\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  40.93523406982422 Current Loss =  79.13075256347656\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  40.93523406982422 Current Loss =  64.73712158203125\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  40.93523406982422 Current Loss =  83.47110748291016\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  28.73937225341797 Current Loss =  81.90437316894531\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  28.73937225341797 Current Loss =  68.84532165527344\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  2 Lowest Loss found so far =  28.73937225341797 Current Loss =  82.40225982666016\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  28.73937225341797 Current Loss =  81.452880859375\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  2 Lowest Loss found so far =  28.73937225341797 Current Loss =  78.90827178955078\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  28.73937225341797 Current Loss =  78.15534973144531\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  28.73937225341797 Current Loss =  83.60720825195312\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  28.73937225341797 Current Loss =  76.69095611572266\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  28.73937225341797 Current Loss =  82.19627380371094\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  19.91118812561035 Current Loss =  78.21468353271484\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  19.91118812561035 Current Loss =  82.03765106201172\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  3 Lowest Loss found so far =  19.91118812561035 Current Loss =  83.54071044921875\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  19.91118812561035 Current Loss =  81.90192413330078\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  3 Lowest Loss found so far =  19.91118812561035 Current Loss =  81.88921356201172\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  19.91118812561035 Current Loss =  78.53331756591797\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  19.91118812561035 Current Loss =  78.3327407836914\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  19.91118812561035 Current Loss =  65.3284912109375\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  19.91118812561035 Current Loss =  82.3436279296875\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  17.219196319580078 Current Loss =  74.97662353515625\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  17.219196319580078 Current Loss =  67.88275146484375\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  4 Lowest Loss found so far =  17.219196319580078 Current Loss =  82.95533752441406\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  4 Lowest Loss found so far =  17.219196319580078 Current Loss =  82.57357025146484\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  4 Lowest Loss found so far =  17.219196319580078 Current Loss =  78.0239028930664\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  17.219196319580078 Current Loss =  74.86674499511719\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  4 Lowest Loss found so far =  17.219196319580078 Current Loss =  82.71661376953125\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  17.219196319580078 Current Loss =  57.43545913696289\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  4 Lowest Loss found so far =  17.219196319580078 Current Loss =  79.54105377197266\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  5 Lowest Loss found so far =  13.594855308532715 Current Loss =  76.39559173583984\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  5 Lowest Loss found so far =  13.594855308532715 Current Loss =  77.37767791748047\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  5 Lowest Loss found so far =  13.594855308532715 Current Loss =  78.51713562011719\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  5 Lowest Loss found so far =  13.594855308532715 Current Loss =  82.72657775878906\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  5 Lowest Loss found so far =  13.594855308532715 Current Loss =  81.45623779296875\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  5 Lowest Loss found so far =  13.594855308532715 Current Loss =  73.36661529541016\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  5 Lowest Loss found so far =  13.594855308532715 Current Loss =  80.18936920166016\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  5 Lowest Loss found so far =  13.594855308532715 Current Loss =  77.00657653808594\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  5 Lowest Loss found so far =  13.594855308532715 Current Loss =  81.2210693359375\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "Tapprox_greedy.shape =  torch.Size([3, 3, 3, 3])\n",
      "len(yi_approxSet_greedy) =  7\n",
      "t =  7 RMSE_RW =  0\n",
      "numParam_greedy= 13\n",
      "r_greedy =  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [2, 1, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 13\n",
      "k =  0 Lowest Loss found so far =  66.513671875 Current Loss =  82.65298461914062\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  66.513671875 Current Loss =  81.40969848632812\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  0 Lowest Loss found so far =  66.513671875 Current Loss =  79.72728729248047\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  0 Lowest Loss found so far =  66.513671875 Current Loss =  72.08161926269531\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  66.513671875 Current Loss =  83.6436996459961\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 17\n",
      "k =  0 Lowest Loss found so far =  65.80760192871094 Current Loss =  82.52976989746094\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  31.6014461517334 Current Loss =  75.58438873291016\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  31.6014461517334 Current Loss =  65.93778228759766\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  31.6014461517334 Current Loss =  79.77984619140625\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  31.6014461517334 Current Loss =  81.87310791015625\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  1 Lowest Loss found so far =  31.6014461517334 Current Loss =  82.45409393310547\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  31.6014461517334 Current Loss =  78.84554290771484\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  31.6014461517334 Current Loss =  78.1011962890625\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  1 Lowest Loss found so far =  31.6014461517334 Current Loss =  68.42416381835938\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  1 Lowest Loss found so far =  31.6014461517334 Current Loss =  80.09830474853516\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  15.886763572692871 Current Loss =  82.057861328125\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  15.886763572692871 Current Loss =  66.6854248046875\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  2 Lowest Loss found so far =  15.886763572692871 Current Loss =  79.59817504882812\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  15.886763572692871 Current Loss =  78.25191497802734\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  2 Lowest Loss found so far =  15.886763572692871 Current Loss =  82.82535552978516\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  15.886763572692871 Current Loss =  79.27071380615234\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  15.886763572692871 Current Loss =  78.43172454833984\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  2 Lowest Loss found so far =  15.886763572692871 Current Loss =  75.27423858642578\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  2 Lowest Loss found so far =  15.886763572692871 Current Loss =  83.60297393798828\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  13.361574172973633 Current Loss =  70.86188507080078\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  13.361574172973633 Current Loss =  67.946533203125\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  3 Lowest Loss found so far =  13.361574172973633 Current Loss =  79.27810668945312\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  13.361574172973633 Current Loss =  81.14485931396484\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  3 Lowest Loss found so far =  13.361574172973633 Current Loss =  82.66251373291016\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  13.361574172973633 Current Loss =  77.18437194824219\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  13.361574172973633 Current Loss =  79.44203186035156\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  3 Lowest Loss found so far =  13.361574172973633 Current Loss =  63.8234977722168\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  3 Lowest Loss found so far =  13.361574172973633 Current Loss =  82.02130126953125\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "r_greedy =  [1, 1, 2, 1, 1, 1, 1, 1]\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  6.120943069458008 Current Loss =  74.29689025878906\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  6.120943069458008 Current Loss =  72.06251525878906\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  4 Lowest Loss found so far =  6.120943069458008 Current Loss =  80.39322662353516\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  4 Lowest Loss found so far =  6.120943069458008 Current Loss =  83.58550262451172\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  4 Lowest Loss found so far =  6.120943069458008 Current Loss =  80.59015655517578\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  6.120943069458008 Current Loss =  77.3907470703125\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  4 Lowest Loss found so far =  6.120943069458008 Current Loss =  80.00503540039062\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  4 Lowest Loss found so far =  6.120943069458008 Current Loss =  68.03193664550781\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  4 Lowest Loss found so far =  6.120943069458008 Current Loss =  81.67792510986328\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  5 Lowest Loss found so far =  6.120943069458008 Current Loss =  8.587061882019043\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  5 Lowest Loss found so far =  6.120943069458008 Current Loss =  71.0235595703125\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  5 Lowest Loss found so far =  6.120943069458008 Current Loss =  67.18215942382812\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  5 Lowest Loss found so far =  6.120943069458008 Current Loss =  80.3183364868164\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  5 Lowest Loss found so far =  6.120943069458008 Current Loss =  81.12026977539062\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  5 Lowest Loss found so far =  6.120943069458008 Current Loss =  81.93147277832031\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  5 Lowest Loss found so far =  6.120943069458008 Current Loss =  74.95158386230469\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  5 Lowest Loss found so far =  6.120943069458008 Current Loss =  81.80886840820312\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  5 Lowest Loss found so far =  6.120943069458008 Current Loss =  65.1096420288086\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  5 Lowest Loss found so far =  6.120943069458008 Current Loss =  82.3183822631836\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  6 Lowest Loss found so far =  6.120943069458008 Current Loss =  7.273891925811768\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  6 Lowest Loss found so far =  6.120943069458008 Current Loss =  72.6371841430664\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  6 Lowest Loss found so far =  6.120943069458008 Current Loss =  71.18704223632812\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  6 Lowest Loss found so far =  6.120943069458008 Current Loss =  81.18770599365234\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  6 Lowest Loss found so far =  6.120943069458008 Current Loss =  82.39813995361328\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 13\n",
      "k =  6 Lowest Loss found so far =  6.120943069458008 Current Loss =  79.03133392333984\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  6 Lowest Loss found so far =  6.120943069458008 Current Loss =  74.72039031982422\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  6 Lowest Loss found so far =  6.120943069458008 Current Loss =  83.45494842529297\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 19\n",
      "k =  6 Lowest Loss found so far =  6.120943069458008 Current Loss =  68.21540069580078\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "numParam_greedy= 17\n",
      "k =  6 Lowest Loss found so far =  6.120943069458008 Current Loss =  82.75764465332031\n",
      "Loss previous is less than current, so no rank update is made at this iteration\n",
      "total number of parameters for best chosen rank =  19\n",
      "Tapprox_greedy.shape =  torch.Size([3, 3, 3, 3])\n",
      "len(yi_approxSet_greedy) =  7\n"
     ]
    }
   ],
   "source": [
    "            ##main script for plotting RMSE vs outer loop for greedy and Random walk############\n",
    "\n",
    "numOuter_iter1 = [1]  #[2,3,4,5]\n",
    "RMSE_greedyList = []\n",
    "RMSE_RW_List = []\n",
    "RMSE_Stoch_List = []\n",
    "\n",
    "r0 = 1\n",
    "r1 = 1\n",
    "r2 = 1\n",
    "r3 = 1\n",
    "r4 = 1\n",
    "r5 = 1\n",
    "r6 = 1\n",
    "r7 = 1\n",
    "maxParam1 = d1*d2*d3*d4\n",
    "print('maxParam allowed = ', maxParam1)\n",
    "\n",
    "#Greedy approach: initialize parameters\n",
    "#noise =  1e-6\n",
    "A_0 = torch.rand(r1,d1,r0,r6)   # + torch.rand(r1,d1,r0,r6)*noise\n",
    "B_0 = torch.rand(r0,d2,r3,r7)   # + torch.rand(r0,d2,r3,r7)*noise\n",
    "C_0 = torch.rand(r1,d3,r2,r5)   # + torch.rand(r1,d3,r2,r5)*noise\n",
    "D_0 = torch.rand(r3,d4,r2,r4)   # + torch.rand(r3,d4,r2,r4)*noise\n",
    "G_0 = torch.rand(r4,r5,r6,r7)   # + torch.rand(r4,r5,r6,r7)*noise\n",
    "TensorList1 = [A_0,B_0,C_0,D_0,G_0] \n",
    "TensorList_temp1 = [A_0,B_0,C_0,D_0,G_0] #TensorList[:]\n",
    "\n",
    "#RandomWalk\n",
    "yi_approxSet_RW = randomWalk(TensorList1, maxParam1, Xi_test)\n",
    "\n",
    "#stochastic\n",
    "iterNum1=100   #500\n",
    "max_numShot1 = 50 \n",
    "maxRank1=5  # 1<=r(i)<=maxR\n",
    "\n",
    "#RMSE for Random walk\n",
    "yi_approxSet_RW = randomWalk(TensorList1, maxParam1,  Xi_test)\n",
    "RMSE_RW = sqrt(mean_squared_error(yi_test,yi_approxSet_RW))   #single point\n",
    "\n",
    "#RMSE for greedy\n",
    "#num_Outer_loop = [2,3,4]\n",
    "for t in range(1,len(yi_approxSet_RW)+1):   #len(RMSE_RW_List) = number of outer iterations for greedy i.e. number of  discrete optimizationloop\n",
    "    print('t = ', t, 'RMSE_RW = ', len(RMSE_RW_List))\n",
    "    yi_approxSet_greedy, greedy_loss_List = greedyMethod(indxList1, maxParam1, t, TensorList1, TensorList_temp1)\n",
    "    RMSE_greedy = sqrt(mean_squared_error(yi_test,yi_approxSet_greedy))\n",
    "    RMSE_greedyList.append(RMSE_greedy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nextDirection =  1\n",
      "next direction = 1 r_RW =  [1, 2, 1, 1, 1, 1, 1, 1]\n",
      "Random Walk: numParam =  13 maxNumParam of target tensor =  81\n",
      "nextDirection =  1\n",
      "next direction = 1 r_RW =  [1, 2, 1, 1, 1, 1, 2, 1]\n",
      "Random Walk: numParam =  19 maxNumParam of target tensor =  81\n",
      "nextDirection =  7\n",
      "next direction = 7 r_RW =  [1, 2, 1, 1, 1, 1, 3, 1]\n",
      "Random Walk: numParam =  26 maxNumParam of target tensor =  81\n",
      "nextDirection =  3\n",
      "next direction = 3 r_RW =  [1, 2, 1, 2, 1, 1, 3, 1]\n",
      "Random Walk: numParam =  33 maxNumParam of target tensor =  81\n",
      "nextDirection =  7\n",
      "next direction = 7 r_RW =  [1, 3, 1, 2, 1, 1, 3, 1]\n",
      "Random Walk: numParam =  39 maxNumParam of target tensor =  81\n",
      "nextDirection =  3\n",
      "next direction = 3 r_RW =  [1, 4, 1, 2, 1, 1, 3, 1]\n",
      "Random Walk: numParam =  51 maxNumParam of target tensor =  81\n",
      "nextDirection =  4\n",
      "next direction = 4 r_RW =  [1, 4, 1, 3, 1, 1, 3, 1]\n",
      "Random Walk: numParam =  63 maxNumParam of target tensor =  81\n",
      "nextDirection =  3\n",
      "next direction = 3 r_RW =  [2, 4, 1, 3, 1, 1, 3, 1]\n",
      "Random Walk: numParam =  69 maxNumParam of target tensor =  81\n",
      "\n",
      "program finished! cant perform another loop else will get numParameters > maxParam\n"
     ]
    }
   ],
   "source": [
    "yi_approxSet_RW = randomWalk(TensorList1, maxParam1,  Xi_test)\n",
    "RMSE_RW = sqrt(mean_squared_error(yi_test,yi_approxSet_RW))   #single point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65.80760192871094, 31.6014461517334, 15.886763572692871, 13.361574172973633, 6.120943069458008, 6.120943069458008, 6.120943069458008]\n"
     ]
    }
   ],
   "source": [
    "print(greedy_loss_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e2b50b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##PLOT FOR RANDOM WALK. X-AXIS = total number of steps and Y-axis = LostList[-1]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(RMSE_greedyList, 'og--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
